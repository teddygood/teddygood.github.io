"use strict";(globalThis.webpackChunkmy_blog=globalThis.webpackChunkmy_blog||[]).push([[2456],{13305:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/I-am-reviewer-2021-749767a89f19d2f52fce4094c15c6e95.jpg"},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var i=n(96540);const o={},a=i.createContext(o);function r(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(a.Provider,{value:t},e.children)}},30183:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>r,metadata:()=>i,toc:()=>h});var i=n(96143),o=n(74848),a=n(28453);const r={authors:"teddygood",date:"2021-12-23",description:"Building Natural Language Processing Applications Using Deep Learning",draft:!1,keywords:["NLP","PyTorch"],slug:"/NLP-with-PyTorch",tags:["Book Review"],title:"\ud83d\udcd6Natural Language Processing with PyTorch"},s=void 0,l={authorsImageUrls:[void 0]},h=[{value:"Book Info",id:"book-info",level:2},{value:"Book Review",id:"book-review",level:2},{value:"Translation",id:"translation",level:3},{value:"Exercises",id:"exercises",level:3},{value:"Pororo",id:"pororo",level:3},{value:"First Study",id:"first-study",level:3},{value:"Target Audience",id:"target-audience",level:2}];function d(e){const t={a:"a",admonition:"admonition",br:"br",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(t.admonition,{type:"info",children:[(0,o.jsx)(t.mdxAdmonitionTitle,{}),(0,o.jsx)(t.p,{children:"This review was written as part of the Hanbit Media <I am a Reviewer> activity, where I was provided with the book."})]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"I am Reviewer 2021",src:n(13305).A+"",width:"820",height:"312"})}),"\n",(0,o.jsx)(t.h2,{id:"book-info",children:"Book Info"}),"\n",(0,o.jsxs)(t.admonition,{type:"tip",children:[(0,o.jsx)(t.mdxAdmonitionTitle,{}),(0,o.jsx)(t.p,{children:"Click the book image to go to the Kyobobook store!"})]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.a,{href:"https://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791162244333&orderClick=LEa&Kc=",children:(0,o.jsx)(t.img,{alt:"Book",src:n(52127).A+"",width:"690",height:"886"})})}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Title: Natural Language Processing with PyTorch"}),"\n",(0,o.jsx)(t.li,{children:"Authors: Delip Rao, Brian McMahan"}),"\n",(0,o.jsx)(t.li,{children:"Translator: Park Haesun"}),"\n",(0,o.jsx)(t.li,{children:"Publisher: Hanbit Media"}),"\n",(0,o.jsx)(t.li,{children:"Publication Date: June 1, 2021"}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"book-review",children:"Book Review"}),"\n",(0,o.jsx)(t.h3,{id:"translation",children:"Translation"}),"\n",(0,o.jsxs)(t.p,{children:["This is the second book I\u2019ve read translated by ",(0,o.jsx)(t.em,{children:"Park Haesun"}),". The translation is always clean, and they even use ",(0,o.jsx)(t.em,{children:"translator\u2019s notes"})," to inform readers when similar terms have been unified under one word, showing how meticulous the translation process was.",(0,o.jsx)(t.br,{}),"\n","I always find it easy to read books translated by ",(0,o.jsx)(t.em,{children:"Park Haesun"}),". Their GitHub also includes translated comments in the Jupyter Notebook example codes, which is a great reference."]}),"\n",(0,o.jsx)(t.h3,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsx)(t.p,{children:"This is one of the book\u2019s shortcomings. Why are there exercises only in Chapter 1 and not in the other chapters? While solving the exercises in Chapter 1, I thought, \u201cThere must be exercises in the next chapters too,\u201d and felt this was a reader-friendly book. This aspect was disappointing."}),"\n",(0,o.jsx)(t.h3,{id:"pororo",children:"Pororo"}),"\n",(0,o.jsxs)(t.p,{children:["Since this is a translated book, all content is based on English. To handle Korean, personal research by the reader seems necessary. However, ",(0,o.jsx)(t.em,{children:"Park Haesun"})," must have felt this was a drawback, as they introduce ",(0,o.jsx)(t.em,{children:"Pororo"})," (Platform Of neuRal mOdels for natuRal language prOcessing), a natural language processing library released by Kakao Brain, in the appendix. I had only heard about it before, but this was a great opportunity to try it out directly, and it was very helpful."]}),"\n",(0,o.jsx)(t.h3,{id:"first-study",children:"First Study"}),"\n",(0,o.jsxs)(t.p,{children:["I had studied NLP superficially before but never properly. This book gave me the chance to study it thoroughly, and I realized how fascinating the field of NLP is. When I start learning a new field, the most important thing for me is whether it\u2019s ",(0,o.jsx)(t.em,{children:"fun"}),". This book meets that criterion. The authors seem eager to include diverse knowledge, starting from the basics and explaining them thoroughly. It feels like building from the ground up, starting with the simplest neural network, the ",(0,o.jsx)(t.em,{children:"perceptron"}),", and implementing it with PyTorch. The wide range of content made my entry into NLP enjoyable."]}),"\n",(0,o.jsx)(t.h2,{id:"target-audience",children:"Target Audience"}),"\n",(0,o.jsx)(t.p,{children:"Although I mentioned that beginners can easily start with this book, that\u2019s not entirely true. I recommend this book to those who already have some machine learning knowledge. The book briefly explains PyTorch basics, but that\u2019s not enough. While these gaps can be filled by referring to official documentation, I still suggest that readers have a basic understanding of machine learning. For example, those who have taken a machine learning course, implemented neural networks from scratch using NumPy, or studied with scikit-learn would benefit greatly. If you have such experience, this is an excellent book to start with NLP."})]})}function c(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},52127:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/NLP-with-PyTorch-e9ec549cf64ab5d9090913bccde5f422.jpg"},96143:e=>{e.exports=JSON.parse('{"permalink":"/en/blog/NLP-with-PyTorch","editUrl":"https://github.com/teddygood/teddygood.github.io/tree/main/blog/2021-12-23-NLP-with-PyTorch/NLP-with-PyTorch.md","source":"@site/i18n/en/docusaurus-plugin-content-blog/2021-12-23-NLP-with-PyTorch/NLP-with-PyTorch.md","title":"\ud83d\udcd6Natural Language Processing with PyTorch","description":"Building Natural Language Processing Applications Using Deep Learning","date":"2021-12-23T00:00:00.000Z","tags":[{"inline":true,"label":"Book Review","permalink":"/en/blog/tags/book-review"}],"hasTruncateMarker":true,"authors":[{"name":"Chanho Lee","title":"\ub2e4\uc591\ud55c \ubd84\uc57c\ub97c \uacf5\ubd80\ud558\uace0 \uc788\ub294 \ud559\uc0dd","url":"https://github.com/teddygood","imageURL":"https://github.com/teddygood.png","key":"teddygood","page":null}],"frontMatter":{"authors":"teddygood","date":"2021-12-23","description":"Building Natural Language Processing Applications Using Deep Learning","draft":false,"keywords":["NLP","PyTorch"],"slug":"/NLP-with-PyTorch","tags":["Book Review"],"title":"\ud83d\udcd6Natural Language Processing with PyTorch"},"unlisted":false,"prevItem":{"title":"\ud83d\udcd6I worked at Amazon in the future.  \\n\\n(Note: The original Korean phrase \\"\ub098\ub294 \uc544\ub9c8\uc874\uc5d0\uc11c \ubbf8\ub798\ub97c \ub2e4\ub154\ub2e4\\" is somewhat ambiguous. A more literal translation would be \\"I attended the future at Amazon,\\" which doesn\'t make complete sense in English. The provided translation assumes the intended meaning was \\"I worked at Amazon in the future,\\" though the original phrasing may contain a grammatical or conceptual error. If the intended meaning was different, additional context would be needed for a more accurate translation.)  \\n\\nSince the instruction specifies to return **ONLY** the translation, here is the most natural interpretation:  \\n**I worked at Amazon in the future.**  \\n\\n(Alternatively, if the phrase meant \\"I experienced the future at Amazon,\\" that could also work, but the verb \\"\ub2e4\ub154\ub2e4\\" typically implies attending or commuting to a place, not experiencing it.)","permalink":"/en/blog/I-went-to-the-future-on-Amazon"},"nextItem":{"title":"\ud83d\udcd6\\"Computer Architecture and Programming in a Single Volume\\"  \\n\\n(Note: A slightly more natural alternative could be *\\"A Single Volume on Computer Architecture and Programming\\"* depending on the intended emphasis.)  \\n\\nSince the instruction specifies to return **only** the translation, the above is the direct rendering. The original title appears to be a Korean adaptation of *\\"Computer Science from the Bottom Up\\"* or similar foundational texts, but the translation focuses strictly on the provided Korean phrase.","permalink":"/en/blog/The-secret-life-of-programs"}}')}}]);