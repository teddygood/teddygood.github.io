<!doctype html>
<html lang="ko-KR" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">[논문 리뷰] OrchestrationBench: LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios @ Chanho Lee</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://teddygood.github.io/blog/OrchestrationBench"><meta data-rh="true" property="og:locale" content="ko_KR"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="[논문 리뷰] OrchestrationBench: LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios @ Chanho Lee"><meta data-rh="true" name="description" content="LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios 논문 리뷰"><meta data-rh="true" property="og:description" content="LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios 논문 리뷰"><meta data-rh="true" name="keywords" content="orchestration,agent,llm,benchmark,planning"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2026-02-04T14:57:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/teddygood"><meta data-rh="true" property="article:tag" content="Paper Review,LLM,Agent"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://teddygood.github.io/blog/OrchestrationBench"><link data-rh="true" rel="alternate" href="https://teddygood.github.io/blog/OrchestrationBench" hreflang="ko-KR"><link data-rh="true" rel="alternate" href="https://teddygood.github.io/en/blog/OrchestrationBench" hreflang="en"><link data-rh="true" rel="alternate" href="https://teddygood.github.io/blog/OrchestrationBench" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://3GO7VFCZS7-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://teddygood.github.io/blog/OrchestrationBench","mainEntityOfPage":"https://teddygood.github.io/blog/OrchestrationBench","url":"https://teddygood.github.io/blog/OrchestrationBench","headline":"[논문 리뷰] OrchestrationBench: LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios","name":"[논문 리뷰] OrchestrationBench: LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios","description":"LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios 논문 리뷰","datePublished":"2026-02-04T14:57:00.000Z","author":{"@type":"Person","name":"Chanho Lee","description":"다양한 분야를 공부하고 있는 학생","url":"https://github.com/teddygood","image":"https://github.com/teddygood.png"},"keywords":["orchestration","agent","llm","benchmark","planning"],"isPartOf":{"@type":"Blog","@id":"https://teddygood.github.io/blog","name":"블로그"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Chanho Lee RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Chanho Lee Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EFT0SBFJCH"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EFT0SBFJCH",{})</script>



<link rel="search" type="application/opensearchdescription+xml" title="Chanho Lee" href="/opensearch.xml">
<link rel="alternate" type="application/rss+xml" href="/projects/rss.xml" title="Chanho Lee Projects RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/projects/atom.xml" title="Chanho Lee Projects Atom Feed">
<link rel="alternate" type="application/json" href="/projects/feed.json" title="Chanho Lee Projects JSON Feed">
<link rel="stylesheet" href="/katex/katex.min.css"><link rel="stylesheet" href="/assets/css/styles.73e7d64c.css">
<script src="/assets/js/runtime~main.de165cb8.js" defer="defer"></script>
<script src="/assets/js/main.19928bb6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-new.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-new.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Chanho Lee</b></a><a class="navbar__item navbar__link" href="/wiki/introduction">Wiki</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a class="navbar__item navbar__link" href="/blog/archive">Archive</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/blog/OrchestrationBench" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko-KR">한국어</a></li><li><a href="/en/blog/OrchestrationBench" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li></ul></div><a href="https://github.com/teddygood" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><a href="https://www.linkedin.com/in/teddygood/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="LinkedIn Account"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="검색 (Meta+k)" aria-keyshortcuts="Meta+k"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 24 24" aria-hidden="true"><circle cx="11" cy="11" r="8" stroke="currentColor" fill="none" stroke-width="1.4"></circle><path d="m21 21-4.3-4.3" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">검색</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="최근 블로그 문서 둘러보기"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent Posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2026</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/OrchestrationBench">[논문 리뷰] OrchestrationBench: LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Linked-List">🤔링크드 리스트는 어디에 사용되는 걸까</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-engineering">📖 AI Engineering</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/hands-on-llm">📖 핸즈온 LLM</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Technical-Interview-Notes-for-Developers">📖 개발자 기술 면접 노트</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/geultto-Recap">🎬 처음이자 마지막 글또 끝</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/deep-learning-from-scratch-remastered">📖 밑바닥부터 시작하는 딥러닝 1(리마스터판)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Hands-on-generative-AI-dev-with-AWS-Bedrock">📖 Amazon Bedrock으로 시작하는 실전 생성형 AI 개발</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2024-Recap">✨2024 회고</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Nov-Recap">✨11월 회고</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">[논문 리뷰] OrchestrationBench: LLM-Driven Agentic Planning and Tool Use in Multi-Domain Scenarios</h1><div class="container_mt6G margin-vert--md"><time datetime="2026-02-04T14:57:00.000Z">2026년 2월 4일</time></div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/teddygood" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/teddygood.png" alt="Chanho Lee"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/teddygood" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp" translate="no">Chanho Lee</span></a></div><small class="authorTitle_nd0D" title="다양한 분야를 공부하고 있는 학생">다양한 분야를 공부하고 있는 학생</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><blockquote>
<p>ICLR 2026. [<a href="https://openreview.net/forum?id=Oljnxmf4pc&amp;noteId=NyL52JeO4j" target="_blank" rel="noopener noreferrer" class="">Paper</a>] [<a href="https://github.com/kakao/OrchestrationBench" target="_blank" rel="noopener noreferrer" class="">Github</a>]</p>
</blockquote>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="들어가며">들어가며<a href="#들어가며" class="hash-link" aria-label="들어가며에 대한 직접 링크" title="들어가며에 대한 직접 링크" translate="no">​</a></h2>
<p>최근 moltbot(현 openclaw), oh-my-opencode와 같은 서비스가 핫해지면서 읽으면 재밌을 것 같다는 생각에 읽고 리뷰합니다.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="간단-요약">간단 요약<a href="#간단-요약" class="hash-link" aria-label="간단 요약에 대한 직접 링크" title="간단 요약에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class="">실제 multi-domain 환경에서 LLM 오케스트레이션을 평가하기 위한 이중 언어(한국어, 영어) 벤치마크를 소개합니다.</li>
<li class="">workflow planning과 tool execution으로 분리하고 Graph Edit Distance(GED)와 같은 structured metric을 사용합니다.</li>
<li class="">이 벤치마크는 constraint validation과 dynamic revision을 포함하는 17개 domain과 거의 100개의 tool로 구성된 수동으로 만든 데이터셋을 포함합니다.</li>
<li class="">실험 결과 일관된 tool execution은 확인되었지만 planning 단계에서는 상당한 변동성이 나타나 structured 평가의 필요성을 강조합니다.</li>
<li class="">새로운 domain, tool, deployment context로 확장 가능한 벤치마크로 설계되었습니다.</li>
</ol>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Introduction에 대한 직접 링크" title="Introduction에 대한 직접 링크" translate="no">​</a></h2>
<p>기존 벤치마크는 대부분 단순화되어 있거나 domain이 격리된 환경에서 작동하기에 서비스 준비가 된 LLM에 필요한 오케스트레이션 능력을 확인할 수 없습니다. 이런 gap을 해소하기 위해 현실적인 서비스 환경에서 LLM을 평가하기 위해 이중 언어 벤치마크인 OrchestrationBench를 소개합니다. 이 벤치마크는 workflow planning과 constraint-aware tool execution을 강조하는 포괄적인 평가 프로토콜을 정의합니다. workflow planning 경우에는 평가는 workflow cosntruction에 공식화됩니다. 각 workflow는 Directed Acyclic Graph(DAG)로 표현됩니다. constraint-aware tool execution은 평가는 tool calling의 syntactic correctness를 넘어섭니다.</p>
<p><img decoding="async" loading="lazy" alt="Architecture" src="/assets/images/01-architecture-af5ee1be1d55bf888398574d8ae58af3.png" width="833" height="402" class="centered_bfhO img_ev3q"></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="related-work">Related Work<a href="#related-work" class="hash-link" aria-label="Related Work에 대한 직접 링크" title="Related Work에 대한 직접 링크" translate="no">​</a></h2>
<p>논문에서는 관련 연구를 네 가지 영역으로 분류합니다.</p>
<p><strong>Tool Execution Benchmarks</strong><br>
<!-- -->BFCL, API-Bank, T-Eval, ToolBench 등은 에이전트가 task를 분해하고 적절한 tool이나 API를 invoke하는 능력을 평가합니다.</p>
<p><strong>Single-agent Task Performance Benchmarks</strong><br>
<!-- -->TaskBench, τ-bench, GAIA, WebArena, OSWorld 등은 single agent가 특정 환경에서 task을 완료하는 능력을 평가합니다. 이런 벤치마크들은 여러 domain에 걸쳐 LLM의 agentic task execution 능력을 측정한다는 점에서 가치가 있습니다. 그러나 OrchestrationBench는 이런 연구들과 다르게 주로 개별 에이전트 성능보다는 LLM-to-LLM 협업에 초점을 맞추며, 특히 메인 모델이 전문 LLM을 오케스트레이션하고 호출하는 시스템을 설계합니다.</p>
<p><strong>Tool Safety Benchmarks</strong><br>
<!-- -->ToolEmu, R-Judge, SafeToolBench는 위험한 요청을 거부하는 능력을 평가합니다. 더 자세히 설명하면 ToolEmu는 single agent, R-Judge, SafeToolBench는 multi-turn agent의 경우입니다. 여기서 ToolEmu는 복잡한 다단계 계획 수행 능력보다는 emulate된 환경 내 개별 tool call의 safety alignment에 초점을 맞춘다고 합니다. 그러나 OrchestrationBench는 main LLM이 사용 가능한 sub-LLM의 functional descriptions과 constraints를 올바르게 이해함으로써 실행 불가능한 요청을 거부할 수 있는지 테스트하고, safety과는 다른 차원의 functional feasibility에 대한 평가를 다룹니다.</p>
<p><strong>Agentic Planning Benchmarks</strong><br>
<!-- -->다양한 추상화 수준에서 계획 및 조정 능력을 평가하는 벤치마크입니다.
PlanBench, MultiAgentBench, REALM-Bench 등 다양한 벤치마크가 있습니다. 이런 벤치마크들이 에이전트의 plan이나 tool calling 능력을 테스트하지만 OrchestrationBench는 main LLM이 natural language capability description에 기반하여 전문화된 서브 LLM을 동적으로 조정하는 오케스트레이터 역할을 하는 계층적인 LLM-to-LLM 오케스트레이션 과제를 제시합니다. workflow planning을 constraint-aware execution과 분리하는 diagnostic evaluation를 제공하여 상용 챗봇 배포에 필요한 오케스트레이션 기능에 대한 유니크한 평가를 제공합니다.</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/02-related-work-7a35f3696610d9073962318e3264a417.png" width="1848" height="578" class="centered_bfhO img_ev3q"></p>
<p>OrchestrationBench는 이 모든 평가를 만족하는 유일한 벤치마크라고 합니다.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-orchestrationbench-framework">The OrchestrationBench Framework<a href="#the-orchestrationbench-framework" class="hash-link" aria-label="The OrchestrationBench Framework에 대한 직접 링크" title="The OrchestrationBench Framework에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-the-complexity-of-evaluating-llms-in-real-world-environments">1. The Complexity of Evaluating LLMs in Real-World Environments<a href="#1-the-complexity-of-evaluating-llms-in-real-world-environments" class="hash-link" aria-label="1. The Complexity of Evaluating LLMs in Real-World Environments에 대한 직접 링크" title="1. The Complexity of Evaluating LLMs in Real-World Environments에 대한 직접 링크" translate="no">​</a></h3>
<p>실제 서비스 환경에서 LLM 평가는 단순한 QA를 넘어서는 복잡한 도전입니다. 다음 사용자 요청을 생각해봅시다.</p>
<blockquote>
<p>&quot;서울행 항공편 예약하고, COEX 근처 호텔 찾아서, 일정을 팀에게 공유해줘.&quot;</p>
</blockquote>
<p>이 요청을 처리하려면 아래와 같은</p>
<ol>
<li class=""><strong>multi-steep planning</strong>: 일정 공유는 예약 완료 후에만 가능</li>
<li class=""><strong>dynamic adaptation</strong>: 사용자가 &quot;아침 비행기로 바꿔줘&quot;라고 수정 요청 시 대응</li>
<li class=""><strong>constraint validation</strong>: &quot;4시 10분에 치과 예약&quot;에 대해 시스템 제약(정시/30분 단위만 가능)을 인지하고 대안 제시</li>
</ol>
<p>이런 시나리오는 기존의 정적인 벤치마크가 잡지 못하는 planning, adaptation, constraint-aware execution의 복잡하게 얽힌 과제를 강조합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-orchestrationbench-architecture">2. OrchestrationBench Architecture<a href="#2-orchestrationbench-architecture" class="hash-link" aria-label="2. OrchestrationBench Architecture에 대한 직접 링크" title="2. OrchestrationBench Architecture에 대한 직접 링크" translate="no">​</a></h3>
<p>OrchestrationBench는 영어와 한국어 즉, 이중 언어 데이터셋을 갖춘 포괄적인 평가 프레임워크를 도입합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="21-advanced-planning-and-coordination">2.1 Advanced Planning and Coordination<a href="#21-advanced-planning-and-coordination" class="hash-link" aria-label="2.1 Advanced Planning and Coordination에 대한 직접 링크" title="2.1 Advanced Planning and Coordination에 대한 직접 링크" translate="no">​</a></h4>
<p>아래를 보면 알 수 있듯이 오케스트레이션을 각 task의 execution 상태, 종속성 관계, step-level planning을 정의하는 structured workflow schema로 형식화합니다. 이런 구조는 sequential 및 parallel execution을 관리하고 workflow 간 종속성을 처리하며, execution 중 사용자 상호작용에 적응할 수 있는지 평가할 수 있게 합니다.</p>
<p><strong>Workflow Schema</strong></p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/03-workflow-schema-64ee027002454de7fd9bcd2ccdb9b7c0.png" width="1422" height="324" class="centered_bfhO img_ev3q"></p>
<p><strong>예시</strong>: &quot;내일 서울 출장이에요. 항공편 예약하고, COEX 근처 호텔도 찾아주시고, 일정을 팀에게 공유해주세요.&quot;</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">workflow_1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pending</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> independent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pending</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> travel_agent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">refined_query</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;내일 서울행 출장 항공편 예약&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">workflow_2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pending</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> independent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pending</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> travel_agent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">refined_query</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;COEX 근처 호텔 예약&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">workflow_3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pending</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> dependent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">depend_on</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;workflow_1&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;workflow_2&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pending</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> calendar_agent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">refined_query</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;완료된 일정을 팀에게 공유&quot;</span><br></span></code></pre></div></div>
<p><code>depend_on</code>은 현재 workflow가 시작되기 전에 완료되어야 하는 workflow를 지정합니다. <code>workflow_3</code>은 <code>workflow_1</code>과 <code>workflow_2</code>에 의존하므로, 두 task이 완료된 후에야 실행됩니다.</p>
<p>실제 환경에서 사용자 쿼리는 정적인 task plan을 따르기보다는 동적으로 진화하는 경우가 많습니다. OrchestrationBench는 모델이 추가적인 tool이 필요할 때 새로운 workflow를 생성하고 explicit confirmation이나 sub-task로의 분기가 필요할 때 workflow를 분할함으로써 유연하게 조정할 수 있는지를 평가합니다. 예를 들어 사용자가 예약된 요청을 수정하거나 대화 중에 새로운 조건을 추가하는 경우 모  델은 이전 단계와의 일관성을 유지하면서 workflow를 업데이트하거나 확장해야 합니다. 명확한 기준은 workflow를 분할하거나 통합해야 하는 시점을 결정합니다. 독립적인 요청(e.g., 항공편 일정과 호텔추천 모두 요청하는 경우) 또는 중간 확인이 필요한 task(e.g., 예약 전에 추천 승인)는 별도의 워커플로로 처리됩니다. 반대로 일관되고 하나의 목표에 기여하는 task는 하나의 workflow 내에 유지됩니다. 예를 들어 유명인의 별자리를 결정하기 전에 생일을 확인하는 경우입니다.</p>
<p>즉, 이 프레임워크는 모델이 계획할 뿐만 아니라 실제 상호작용적인 시나리오에 맞춰 workflow를 조정하고 중단하고 다시 작동하는 능력을 자세하게 평가할 수 있도록 합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="22-comprehensive-tool-use">2.2. Comprehensive Tool Use<a href="#22-comprehensive-tool-use" class="hash-link" aria-label="2.2. Comprehensive Tool Use에 대한 직접 링크" title="2.2. Comprehensive Tool Use에 대한 직접 링크" translate="no">​</a></h4>
<p>tool execution 평가는 단순히 tool call 정확도를 검증하는 수준을 넘어, 서비스 수준 상호작용 과정 전체를 포괄합니다.
이는 모델이 tool을 올바르게 invoke하는지 뿐만 아니라, 언제 tool use가 필요한지, 언제는 추가 tool 없이 직접 정보를 제공할 수 있는지, 그리고 사용자 입력이 불충분하거나 모호한 경우를 인지하여 능동적으로 추가 설명을 요청할 수 있는지를 평가합니다. 이러한 행동은 <code>AWAIT_FOR_USER_INPUT</code> 신호로 표현됩니다.</p>
<p>syntatic correctness를 넘어서서 실제 서비스는 도메인별 비즈니스 규칙을 엄격하게 준수해야 합니다. tool을 실제로 invoke하기 전에, 모델은 pre-execution 검증을 수행하며, 필요한 제약 조건이 충족되지 않았을 경우 <code>TOOL_CONSTRAINT_VIOLATION</code>을 발생시킵니다.</p>
<ul>
<li class="">논리적 일관성 유지<!-- -->
<ul>
<li class="">사용자의 요청 내용이 현실적으로 말이 되거나 논리적으로 모순되지 않는지 확인하는 과정</li>
<li class="">e.g., 항공권 예약 시 귀국일이 출발일보다 빠른 것</li>
</ul>
</li>
<li class="">자원 제한 강제<!-- -->
<ul>
<li class="">서비스나 도구가 제공하는 특정 자원의 제약을 사용자의 요청이 준수하는지 확인하는 과정</li>
<li class="">e.g., 특정 물품의 재고 수량을 초과하는 주문 요청, 허용된 예산을 넘어서는 구매 요청</li>
</ul>
</li>
</ul>
<p>LLM은 사용자의 요청이나 추출된 정보에 대해 성공적으로 유효성 검사를 마친 후에야 비로소 올바른 형식의 매개변수를 사용하여 해당 외부 도구를 실행해야 합니다.</p>
<p>모델 성능은 call/reject 분류 매트릭을 통해 측정되고 여기서 <code>AWAIT_FOR_USER_INPUT</code>, <code>TOOL_CONSTRAINT_VIOLATION</code>은 reject 사례를 나타내고 성공적인 execution은 funcion-calling 성능 지표를 사용하여 평가됩니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="23-multi-domain-tool-environments">2.3. Multi-Domain Tool Environments<a href="#23-multi-domain-tool-environments" class="hash-link" aria-label="2.3. Multi-Domain Tool Environments에 대한 직접 링크" title="2.3. Multi-Domain Tool Environments에 대한 직접 링크" translate="no">​</a></h4>
<p>이 벤치마크는 특정 서비스 종속성과는 독립적으로 유지하면서 실제 애플리케이션으로 확장 가능한 17개의 대표적인 서비스 도메인을 정의합니다. 각 도메인은 모델의 고유한 오케스트레이션 및 명령어 수행 능력을 평가할 수 있도록 현실적이면서도 일반화된 시나리오를 중심으로 구축됩니다.</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/04-multi-domain-tools-341eec496f80d6671ee5a8ceb6d6fa2d.png" width="1548" height="1646" class="centered_bfhO img_ev3q"></p>
<p>영어 97개, 한국어 99개의 tool이 있습니다. 한국어에는 주소 로마자 변환, 사주 정보 등과 같은 특수 tool이 추가되어 있습니다. 단순화된 tool 추상화를 사용한 이전 벤치마크들과는 달리 OrchestrationBench는 도메인별 제약 조건과 현실적인 동작을 통합하여 다양한 task에 대한 세밀한 커버리지를 제공하고 실제 서비스 환경을 충실하게 시뮬레이션합니다.</p>
<p>이런 domain들은 집합적으로 세 가지 일반적인 사용자 workflow 유형을 나타냅니다. 이런 분류는 이 벤치마크가 주로 일상적인 소비자 서비스를 반영하는 동시에 유틸리티 및 생산성 맥락으로 확장 가능함을 강조합니다.</p>
<ol>
<li class="">문의 및 정보 task(e.g., 날씨 확인, 장소 찾기, 뉴스 읽기)</li>
<li class="">행동 및 거래 task(e.g., 항공권 예약, 물품 구매)</li>
<li class="">계획 및 조정 task(e.g., 회의 일정 잡기, 메시지 보내기, 배송 준비)</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-dataset-construction">3. Dataset Construction<a href="#3-dataset-construction" class="hash-link" aria-label="3. Dataset Construction에 대한 직접 링크" title="3. Dataset Construction에 대한 직접 링크" translate="no">​</a></h3>
<p>해당 데이터셋은 실제 서비스 오케스트레이션의 복잡성과 현실성을 잡을 수 있도록 설계되었습니다. 진정성과 퀄리티를 보장하기 위해 모든 대화 세션, workflow 및 tool call은 인공적으로 생성한 것이 아닌 훈련된 annotator가 상세한 구축 지침에 따라 직접 생성했습니다. 즉, 대화 흐름, tool 사용 및 제약 조건 처리가 특정 모델의 인공 데이터가 아닌 현실적인 사용자-서비스 상호작용을 충실하게 반영하도록 보장합니다.</p>
<p>아래 표는 domain 선택, 가상 tool 설계, 수동 검토 및 검증을 포함하는 전반적인 구축 파이프라인입니다. 모든 시나리오는 일관성과 정확성을 보장하기 위해 최소 세 명의 annotator에 의해 교차 검증 되었습니다. 통제되고 해석 가능한 평가를 가능하게 하기 위해 모호하거나 다중 솔루션 사례를 제외하고 명확하고 잘 정의된 종속성을 가진 task세어만 데이터를 구축했습니다. 즉, 이 벤치마크는 높은 신뢰성을 달성하는 동시에 단일 모델이나 독점 API에 독립적으로 유지됩니다.</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/05-dataset-construction-f999b66fab602f353e89a6fb9e59a7cd.png" width="1534" height="654" class="centered_bfhO img_ev3q"></p>
<p><strong>시나리오 유형 예시</strong></p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/06-scenario-types-9e6eff6c1979b75e68ae64aa69323400.png" width="1488" height="534" class="centered_bfhO img_ev3q"></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-dataset-scale-and-distribution">4. Dataset Scale and Distribution<a href="#4-dataset-scale-and-distribution" class="hash-link" aria-label="4. Dataset Scale and Distribution에 대한 직접 링크" title="4. Dataset Scale and Distribution에 대한 직접 링크" translate="no">​</a></h3>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/07-dataset-scale-079b5467c508641d73dc4df84879991c.png" width="888" height="228" class="centered_bfhO img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/08-dataset-distribution-ea6733044191206ba0ebe814c0a555b5.png" width="1436" height="1436" class="centered_bfhO img_ev3q"></p>
<p>이 데이터셋은 영어와 한국어 서브셋을 모두 포함하며 규모 면에서 유사합니다. 두 데이터셋 모두 17개의 대표적인 서비스 도메인에 걸쳐 있고, 의도적으로 비대칭적인 tool 분포를 보여줍니다. Places 또는 Entertainment와 같은 넓은 domain은 많은 tool을 포함하지만, Weather나 News 같은 좁은 domain은 현실적인 사용 빈도를 반영하기 위해 간결하게 구성되어 있습니다.</p>
<p>workflow 수준에서 대부분의 세션은 2<del>3개의 workflow와 2</del>3개의 domain을 포함하지만 일부는 최대 7 step까지 확장되거나 4개 이상의 domain에 걸칩니다. 이는 single session이 일반적으로 여러 차례의 planning을 필요로 하며 일부는 최대 7 planning step을 포함하는 걸 보여줍니다. 또한, 두 개 이상의 domain이 자주 포함되는 것은 사용자가 heterogeneous 서비스 간에 전환하는 현실적인 다중 도메인 시나리오를 반영합니다. tool invocation 측면에서 이 데이터셋은 single isolated call보다는 sequential and parallel call 구조가 지배적이어서 실제 task을 완료하는 데 오케스트레이션이 복잡한 걸 확인할 수 있습니다.</p>
<p>이런 분포들은 종합적으로 OrchestrationBench가 광범위한 실제 오케스트레이션 패턴을 다루며, 모델 planning, tool invocation 그리고 adaptive reasoning capabilities에 대한 세밀한 평가를 가능하게 함을 보여줍니다. 이는 벤치마크가 고립된 질의응답 또는 단순한 tool calling을 넘어 현실적이고 constaint-aware 서비스 환경에서의 오케스트레이션 성능 평가를 가능하게 함을 강조합니다.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluation">Evaluation<a href="#evaluation" class="hash-link" aria-label="Evaluation에 대한 직접 링크" title="Evaluation에 대한 직접 링크" translate="no">​</a></h2>
<p>현재의 end-to-end 벤치마크인 AgentBench, GAIA, SWE-bench, τ-bench는 유연성을 제공하지만 복잡한 multi-step task에서 실패 지점을 모호하게 만드는 경우가 많습니다. 이런 한계를 해결하기 위해 각 구성 요소를 독립적으로 분리하고 테스트하는 스탭별 평가를 사용합니 다. 평가는 Planning과 Tool execution 두 가지 주요 단계를 구분합니다. 서브 LLM의 미묘한 동작을 잡기 위해 tool execution을 두 가지 순차적인 평가 기준으로 더 분해합니다. call/reject 분류 정확도와 function calling 성능입니다.</p>
<p><strong>모델</strong><br>
<!-- -->모든 reasoning 모델은 low reasoning 설정으로 구성되었습니다.</p>
<ul>
<li class="">OpenAI GPT Models (gpt-4.1, gpt-4o, gpt-5)</li>
<li class="">Anthropic Claude Models (claude-sonnet-4)</li>
<li class="">Google Gemini Models (gemini-2.5-pro-preview, gemini-2.5-flash-preview)</li>
<li class="">Alibaba Qwen Models (Qwen3 series)</li>
<li class="">Korean Open-Source Models (SKT A.X-4.0, Kakao kanana-1.5, LG AI Research EXAONE-4.0)</li>
</ul>
<p><strong>Evaluation Protocol</strong></p>
<ul>
<li class="">각 타겟 LLM은 평가 시점까지의 전체 대화 기록을 입력으로 제공받는다.</li>
<li class="">병렬적으로 실행되는 LLM들은 정보 누출을 방지하기 위해 서로 분리된 기록에서 작동합니다.</li>
<li class="">순차적으로 실행되는 LLM들은 이전 모델의 출력을 포함한 누적된 대화 기록에 접근합니다.</li>
<li class="">메인 LLM의 workflow 생성은 사용자 입력에 의해서만 트리거됩니다.</li>
<li class="">서브 LLM은 메인 LLM으로부터 전달된 정제된 질의와 사용자가 제공한 추가 설명을 처리한다.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-evaluation-metrics">1. Evaluation Metrics<a href="#1-evaluation-metrics" class="hash-link" aria-label="1. Evaluation Metrics에 대한 직접 링크" title="1. Evaluation Metrics에 대한 직접 링크" translate="no">​</a></h3>
<p>2가지로 나뉘어집니다. 이렇게 분리한 이유는 계획을 잘 세워도 실행에서 틀릴 수 있고, 반대로 단순 호출 정확도는 좋아도 전체 workflow는 망가질 수 있기 때문입니다.</p>
<p><strong>Planning Assessment</strong></p>
<p>workflow 생성 품질을 평가하기 위해 Graph Edit Distance(GED)를 사용합니다. GED는 하나의 그래프를 다른 그래프로 변환하기 위해 필요한 최소 편집 연산(minimum edit operations)의 수를 계산함으로써 구조적 차이(structural differences)를 정량화하며, Advancing Agentic Systems의 방법을 따릅니다. 본 연구에서는 값이 클수록 성능이 우수함을 의미하도록 1−GED를 사용합니다. 우리의 workflow representation은 workflow structure, step assignment(sub-LLM selection), 그리고 execution status를 포함합니다. 우리는 계층적 workflow 점수 평가를 수행하며, 이 중 structural score는 workflow topology의 정확성을 측정하고, component score는 step-level assignments을 평가합니다. 오류 가중치 설정에서는 status errors(0.2)보다 selection errors(0.8)에 더 높은 가중치를 부여합니다. 이는 잘못된 tool을 선택하는 것이 tool execution 상태를 잘못 판단하는 것보다 일반적으로 task 성공에 더 치명적이라는 직관을 반영한 것입니다. 다만, 이러한 가중치는 경험적으로 도출된 것은 아닙니다.</p>
<p><strong>Tool Execution Assessment</strong>
tool execution 능력을 종합적으로 평가하기 위해, 우리는 두 가지 핵심 요소를 분석합니다. 첫째는 모델이 적절한 calling 결정을 내릴 수 있는 능력이며, 둘째는 실제 function execution의 퀄리티입니다. call/reject classification accuracy는 전체 사례 중에서 적절한 reject 결정과 성공적인 function call 시도를 모두 포함한 올바른 결정의 비율을 측정합니다. function calling performance는 function call 단계로 정상적으로 진행된 사례들에 한해 실제 function call의 정확성을 평가하며, 세 가지 세부 지표를 사용합니다. tool 선택 F1, key F1, 그리고 argument F1입니다.</p>
<p>function calling 파라미터 검증은 3단계 접근법을 사용합니다.</p>
<ol>
<li class="">Exact match 비교</li>
<li class="">tool descriptions에 기반한 type/pattern 검증</li>
<li class="">나머지 사례에 대한 semantic 검증</li>
</ol>
<p>모델 bias를 줄이기 위해, 우리는 세 개의 LLM judges — GPT-4.1, Claude Sonnet 4, Gemini 2.5 Flash — 로 구성된 앙상블(ensemble)을 사용하며, temperature는 0.3으로 설정하고 arithmetic mean을 통해 점수를 집계합니다.</p>
<p>LLM judge는 true/false positives and negatives을 분류하며, 이러한 판정 결과는 F1 계산에 통합됩니다. 평가의 신뢰성을 추가로 확보하기 위해, annotator와 LLM judge 간의 judge 간 일치도(inter-rater agreement)를 측정하였고, 그 결과 Cohen’s Kappa 점수 0.63을 얻었으며, 이는 상당한 수준의 일치를 의미합니다. function calling training과의 호환성, 즉 JSON 출력 형식을 유지하기 위해 call rejection과 information requests를 XML 출력 형식으로 구현합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-evaluation-results">2. Evaluation Results<a href="#2-evaluation-results" class="hash-link" aria-label="2. Evaluation Results에 대한 직접 링크" title="2. Evaluation Results에 대한 직접 링크" translate="no">​</a></h3>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/09-evaluation-results-51393a28ec55f6bae8a2806d85655e7a.png" width="1614" height="1522" class="centered_bfhO img_ev3q"></p>
<p>최고 성능은 bold, 차순위 성능은 밑줄로 표시되었습니다. Claude 모델은 <code>anthropic.claude-sonnet-4-20250514-v1:0</code>을 사용하여 AWS Bedrock을 통해 평가되었습니다. workflow 점수는 1-GED로 계산되고 값이 높을수록 성능이 좋습니다.</p>
<p><strong>핵심 발견</strong></p>
<p><strong>Open-Source Model Viability</strong></p>
<p>Qwen3-235B-A22B 같은 오픈소스 dense 모델이 상용 모델에 근접한 성능을 보였습니다. Dense 아키텍처가 Mixture-of-Experts(MoE)보다 Planning 태스크에서 일관되게 우수했습니다.</p>
<p><strong>Model-Specific Specializations</strong></p>
<p>Gemini는 Planning에서 최고(영어 0.850)를 보여줬지만 function calling은 약합니다. Claude-sonnet-4는 Function Calling에서 최고(영어 0.885)를 기록했습니다. GPT-4.1은 균형 잡힌 성능을 보여줍니다. 특히 workflow 생성은 위의 그래프를 보면 알 수 있듯이 영어 및 한국어 데이터셋 모두에서 최상위 모델과 하위 모델 간에 상대적으로 큰 성능 편차를 보이고, 평가된 task들 중에서 planning 능력이 차별화되는 역량입니다.</p>
<p><strong>Planning-Execution Gap</strong></p>
<p>Planning과 Call/Reject 간 상관계수가 영어 0.58, 한국어 0.45로 상대적으로 낮습니다. planning과 decision 간의 연관성이 상대적으로 약합니다. 즉, 모델이 좋은 workflow를 생성하더라도 execution decision-making이 부정확할 수 있습니다.</p>
<p><strong>Language-Dependent Performance</strong></p>
<p>Claude는 영어 Call/Reject decision에서 0.868이지만 한국어에서는 0.759로 하락합니다. 반면 Gemini는 한국어에서 더 강한 성능을 보여줍  니다. 이는 언어별 학습 효과와 이중 언어 평가의 중요성을 나타냅니다.</p>
<p>이러한 결과는 강력한 개별 역량에도 불구하고, planning-execution 간의 차이가 실제 환경에서의 에이전트형 성능을 제한할 수 있음을 보여주며 task-specific and language-aware 모델 선택의 필요성을 강조합니다.</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/assets/images/10-metric-correlation-75d54e15803c1f3175d5c0c1986dd2bc.png" width="1358" height="426" class="centered_bfhO img_ev3q"></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion-and-future-works">Conclusion and Future Works<a href="#conclusion-and-future-works" class="hash-link" aria-label="Conclusion and Future Works에 대한 직접 링크" title="Conclusion and Future Works에 대한 직접 링크" translate="no">​</a></h2>
<p>OrchestrationBench는 현실적인 multi-domain 서비스 환경에서 LLM 오케스트레이션 능력을 평가하는 최초의 이중언어(영어/한국어) 벤치마크입니다. 오케스트레이션을 workflow planning과 tool execution 요소로 분리함으로써 agentic reasoning의 다양한 측면에 걸친 모델 성능에 대한 인사이트를 제공합니다.</p>
<p>핵심 결론은 두 가지입니다.</p>
<ul>
<li class="">workflow planning은 function calling보다 모델 간 성능 격차가 훨씬 크며 오케스트레이션 task에서 신중한 모델 선택이 필요합니다.</li>
<li class="">모델들이 함수 호출은 잘 수행하지만, 실제 환경에서의 tool constraints를 고려해 function call이 적절한지 판단하는 call/reject 분류에서는 어려움을 보입니다.</li>
</ul>
<p>한계도 다음과 같습니다.</p>
<ul>
<li class="">17개 도메인이 모든 오케스트레이션 시나리오를 포착하거나 다른 언어로 일반화하기에는 무리가 있습니다.</li>
<li class="">가상 도구 사용으로 실제 API 통합의 복잡성이 반영되지 않습니다.</li>
<li class="">turn-by-turn 평가는 각 step에서의 execution이 성공적으로 이루어진다고 가정하기에 전체 성능 매트릭을 과대평가할 가능성이 있습니다.</li>
</ul>
<p>향후 방향은 아래와 같습니다.</p>
<ul>
<li class="">MCP 같은 프레임워크를 통한 실제 multi-domain tool 통합</li>
<li class="">planning-execution 갭을 해결하는 학습 방법 개발</li>
<li class="">더 정교한 multi-agent 협업 패턴 지원</li>
</ul></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/paper-review">Paper Review</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm">LLM</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/agent">Agent</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/teddygood/teddygood.github.io/tree/main/blog/2026-02-04-OrchestrationBench/2026-02-04-OrchestrationBench.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="블로그 게시물 탐색"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Linked-List"><div class="pagination-nav__sublabel">다음 게시물</div><div class="pagination-nav__label">🤔링크드 리스트는 어디에 사용되는 걸까</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#들어가며" class="table-of-contents__link toc-highlight">들어가며</a></li><li><a href="#간단-요약" class="table-of-contents__link toc-highlight">간단 요약</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#related-work" class="table-of-contents__link toc-highlight">Related Work</a></li><li><a href="#the-orchestrationbench-framework" class="table-of-contents__link toc-highlight">The OrchestrationBench Framework</a><ul><li><a href="#1-the-complexity-of-evaluating-llms-in-real-world-environments" class="table-of-contents__link toc-highlight">1. The Complexity of Evaluating LLMs in Real-World Environments</a></li><li><a href="#2-orchestrationbench-architecture" class="table-of-contents__link toc-highlight">2. OrchestrationBench Architecture</a></li><li><a href="#3-dataset-construction" class="table-of-contents__link toc-highlight">3. Dataset Construction</a></li><li><a href="#4-dataset-scale-and-distribution" class="table-of-contents__link toc-highlight">4. Dataset Scale and Distribution</a></li></ul></li><li><a href="#evaluation" class="table-of-contents__link toc-highlight">Evaluation</a><ul><li><a href="#1-evaluation-metrics" class="table-of-contents__link toc-highlight">1. Evaluation Metrics</a></li><li><a href="#2-evaluation-results" class="table-of-contents__link toc-highlight">2. Evaluation Results</a></li></ul></li><li><a href="#conclusion-and-future-works" class="table-of-contents__link toc-highlight">Conclusion and Future Works</a></li></ul></div></div></div></div></div></div>
</body>
</html>