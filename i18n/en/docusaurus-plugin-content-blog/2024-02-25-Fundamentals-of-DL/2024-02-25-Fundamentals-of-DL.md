---
authors: teddygood
date: '2024-02-25'
description: 'From Linear Algebra and Probability to Deep Learning with PyTorch: Theory
  and Practice'
draft: false
keywords:
- Deep Learning
- Deep learning
slug: /Fundamentals-of-DL
tags:
- Book Review
title: "\U0001F4D6The Essential Guide to Deep Learning"
---

:::info  
This review was written as part of the Hanbit Media *I am a Reviewer* activity, where I received the book for review purposes.  
:::

![I am Reviewer 2024](../assets/I-am-reviewer-2024.jpg)

## Book Info

:::tip  
Click the book cover to visit the Kyobobook store!  
:::

[![Book](../assets/review/Fundamentals-of-DL.jpg)](https://product.kyobobook.co.kr/detail/S000212175486)

- **Title**: Fundamentals of Deep Learning  
- **Authors**: Nitish Srivastava, Nikhil Buduma, Joe Papa  
- **Translators**: Jaehoon Choi, Seongjae Cha  
- **Editors**: Taeung Sung, Yunho Maeng  
- **Publisher**: Hanbit Media  
- **Publication Date**: February 2, 2024  

<!-- truncate -->

## Intro  

It’s already 2024. Studying deep learning has been challenging so far—and it’s still tough. This year, I’ll keep pushing to learn more about machine learning. There are so many books I want to read. Thanks to Hanbit Media’s *I am a Reviewer* program, my first IT book of 2024 is *Fundamentals of Deep Learning*.  

## Book Review  

### Foundational Math  
The book starts with concise yet essential explanations of linear algebra and probability. However, if you’ve never studied these topics before, you might find them difficult. The explanations are clear, but even I struggled a bit when revisiting them. That’s expected—Chapters 1 and 2 alone could fill a university course. Studying linear algebra and probability beforehand would make this book more rewarding. Still, it was refreshing to revisit these concepts, especially since the authors explain *why* they matter, which motivates readers.  

### Effort from Authors & Translators  
If I were a translator, I’d probably hate translating this book. The sentences are dense and technically challenging. The authors clearly tried to simplify complex math concepts, and the translators must have worked hard to preserve that clarity in Korean. The presence of two editors likely helped polish the text.  

### Korean Terminology  
Since I studied machine learning in English, the heavy use of Korean terms felt awkward at times. However, English equivalents were always provided (e.g., 고유벡터$^{eigenvectors}$, 사후확률$^{posterior \ probability}$, L2 규제화$^{regularization}$). Most terms were translated, while untranslatable ones like *dropout* remained in English. This is unavoidable in translations, but it was a bit disappointing.  

### What Sets This Book Apart  
You’ll notice many footnotes throughout the book—this is a key difference from other deep learning texts. Whenever a key concept appears, the footnotes cite the original research papers. The book feels like a curated summary of foundational papers, explained by the authors. While some details felt like TMI (Too Much Information), the academic tone was engaging. It made sense why the title is *Fundamentals of Deep Learning*.  

### PyTorch  
PyTorch is introduced in Chapter 5. Before that, the book focuses on core deep learning concepts. It doesn’t deeply explain PyTorch—you’ll need to look up specifics elsewhere. That’s fair, since this isn’t a PyTorch tutorial. Familiarity with PyTorch basics (e.g., via [Opentutorials (생활코딩) PyTorch Tutorial](https://tutorials.pytorch.kr/)) would make reading smoother.  

### Broad Coverage  
The book touches on CNNs, RNNs, reinforcement learning, generative models, XAI, and even Neural Turing Machines (NTM). While CNNs and RNNs are well-explained, topics like XAI and NTM felt too brief and challenging. Still, it was interesting to see these fields introduced.  

## Recommended Audience  
This isn’t a beginner-friendly book. If you’re new to deep learning, you might get overwhelmed. However, if you already understand the basics, this book is a great resource for deepening your knowledge. It’s especially useful if you want to revisit concepts with clear, detailed explanations.