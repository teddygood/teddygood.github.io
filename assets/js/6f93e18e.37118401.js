"use strict";(self.webpackChunkmy_blog=self.webpackChunkmy_blog||[]).push([[5999],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>k});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var o=n.createContext({}),u=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=u(e.components);return n.createElement(o.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,o=e.parentName,m=p(e,["components","mdxType","originalType","parentName"]),d=u(a),k=l,c=d["".concat(o,".").concat(k)]||d[k]||s[k]||r;return a?n.createElement(c,i(i({ref:t},m),{},{components:a})):n.createElement(c,i({ref:t},m))}));function k(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,i=new Array(r);i[0]=d;var p={};for(var o in t)hasOwnProperty.call(t,o)&&(p[o]=t[o]);p.originalType=e,p.mdxType="string"==typeof e?e:l,i[1]=p;for(var u=2;u<r;u++)i[u]=a[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},8838:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>s,frontMatter:()=>r,metadata:()=>p,toc:()=>u});var n=a(7462),l=(a(7294),a(3905));const r={title:"Data Engineering \uc2a4\ud130\ub514 2\uc8fc\ucc28",date:"2021-08-30",draft:!1,description:"PseudoLab Data Science Fellowship 1\uae30",sidebar_position:1},i="Inrtroduction to Data Engineering",p={unversionedId:"Group-Study/data-engineering/data-engineer-with-python-week-02",id:"Group-Study/data-engineering/data-engineer-with-python-week-02",title:"Data Engineering \uc2a4\ud130\ub514 2\uc8fc\ucc28",description:"PseudoLab Data Science Fellowship 1\uae30",source:"@site/docs/Group-Study/data-engineering/data-engineer-with-python-week-02.md",sourceDirName:"Group-Study/data-engineering",slug:"/Group-Study/data-engineering/data-engineer-with-python-week-02",permalink:"/docs/Group-Study/data-engineering/data-engineer-with-python-week-02",draft:!1,editUrl:"https://github.com/teddygood/teddygood.github.io/tree/main/docs/Group-Study/data-engineering/data-engineer-with-python-week-02.md",tags:[],version:"current",lastUpdatedAt:1671512338,formattedLastUpdatedAt:"2022\ub144 12\uc6d4 20\uc77c",sidebarPosition:1,frontMatter:{title:"Data Engineering \uc2a4\ud130\ub514 2\uc8fc\ucc28",date:"2021-08-30",draft:!1,description:"PseudoLab Data Science Fellowship 1\uae30",sidebar_position:1},sidebar:"sidebar",previous:{title:"Data Engineering \uc2a4\ud130\ub514 1\uc8fc\ucc28",permalink:"/docs/Group-Study/data-engineering/data-engineer-with-python-week-01"},next:{title:"Data Engineering \uc2a4\ud130\ub514 3\uc8fc\ucc28",permalink:"/docs/Group-Study/data-engineering/data-engineer-with-python-week-03"}},o={},u=[{value:"Introduction to Data Engineering",id:"introduction-to-data-engineering",level:2},{value:"Data engineering toolbox",id:"data-engineering-toolbox",level:2},{value:"Extract, Transform and Load(ETL)",id:"extract-transform-and-loadetl",level:2},{value:"Case Study: DataCamp",id:"case-study-datacamp",level:2}],m={toc:u};function s(e){let{components:t,...a}=e;return(0,l.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"inrtroduction-to-data-engineering"},"Inrtroduction to Data Engineering"),(0,l.kt)("h2",{id:"introduction-to-data-engineering"},"Introduction to Data Engineering"),(0,l.kt)("p",null,"\ucd5c\uc545\uc758 \uc0c1\ud669"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130\ub294 \ud769\uc5b4\uc838\uc788\uc74c"),(0,l.kt)("li",{parentName:"ul"},"\ubd84\uc11d\uc5d0 \ucd5c\uc801\ud654\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc74c"),(0,l.kt)("li",{parentName:"ul"},"\ub808\uac70\uc2dc\ucf54\ub4dc \ub54c\ubb38\uc5d0 \ub370\uc774\ud130\uac00 \uc190\uc0c1\ub418\uc5b4 \uc788\uc74c")),(0,l.kt)("p",null,"data engineer\ub294 data scientist \uc0b6\uc744 \ud3b8\ud558\uac8c \ud568"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uc5ec\ub7ec \uc18c\uc2a4\uc5d0\uc11c \ub370\uc774\ud130\ub97c extract\ud558\uace0 single DB\uc5d0 load"),(0,l.kt)("li",{parentName:"ul"},"\ubd84\uc11d\uc744 \uc704\ud558\uc5ec DB\ub97c \ucd5c\uc801\ud654\ud558\uc5ec \ucffc\ub9ac \uc18d\ub3c4\ub97c \ube60\ub974\uac8c \ub9cc\ub4ec"),(0,l.kt)("li",{parentName:"ul"},"\uc190\uc0c1\ub41c \ub370\uc774\ud130\ub3c4 \uc81c\uac70"),(0,l.kt)("li",{parentName:"ul"},"\ud655\uc7a5\uc744 \uc6d0\ud558\ub294 \ub370\uc774\ud130 \uc911\uc2ec(data-driven) \ud68c\uc0ac\uc5d0\uc11c \uac00\uc7a5 \uac00\uce58\uc788\ub294 \uc0ac\ub78c")),(0,l.kt)("p",null,"\ub370\uc774\ud130 \uc5d4\uc9c0\ub2c8\uc5b4 \uc815\uc758"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"DB\uc640 large-scale processing system \uac19\uc740 architecture\ub97c \uac1c\ubc1c, \uad6c\uc131, \ud14c\uc2a4\ud2b8, \uc720\uc9c0 \uad00\ub9ac\ud558\ub294 \uc5d4\uc9c0\ub2c8\uc5b4"),(0,l.kt)("li",{parentName:"ul"},"\ub9ce\uc740 \uc591\uc758 \ub370\uc774\ud130\ub97c \ucc98\ub9ac"),(0,l.kt)("li",{parentName:"ul"},"\ucef4\ud4e8\ud305\uc744 \uc218\ud589\ud558\ub294 machine cluster\ub97c \uc0ac\uc6a9 \ubc0f \uc124\uc815 -> virtual machine\uc758 cluster",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"cluster: \uace0\uc131\ub2a5 \ucef4\ud4e8\ud305\uc744 \uc704\ud574 \uc5ec\ub7ec \ub2e8\ub9d0\uc758 \ucef4\ud4e8\ud130\ub85c \uad6c\uc131\ub41c \ucef4\ud4e8\ud130 \uc9d1\ud569")))),(0,l.kt)("p",null,"Data Engineer vs Data Scientist"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Data Engineer",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ud655\uc7a5\uac00\ub2a5\ud55c \ub370\uc774\ud130 \uc544\ud0a4\ud14d\ucc98 \uac1c\ubc1c"),(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130 \uc218\uc9d1 \uac04\uc18c\ud654"),(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130\ub97c \uac00\uc838\uc624\ub294 \ud504\ub85c\uc138\uc2a4 \uc124\uc815"),(0,l.kt)("li",{parentName:"ul"},"\uc190\uc0c1\ub41c \ub370\uc774\ud130\ub97c \uc815\ub9ac\ud558\uc5ec \ub370\uc774\ud130 \ubcf4\ud638"),(0,l.kt)("li",{parentName:"ul"},"\ud074\ub77c\uc6b0\ub4dc \uae30\uc220\uc5d0 \uc798 \uc54c\uc544\uc57c \ud568"))),(0,l.kt)("li",{parentName:"ul"},"Data Scientist",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130 \ud328\ud134\uc744 \ucc3e\uae30 \uc704\ud574 \ud558\ub294 \ub370\uc774\ud130 \ub9c8\uc774\ub2dd"),(0,l.kt)("li",{parentName:"ul"},"\ub300\uaddc\ubaa8 \ub370\uc774\ud130\uc14b\uc5d0 \ud1b5\uacc4 \ubaa8\ub378 \uc801\uc6a9"),(0,l.kt)("li",{parentName:"ul"},"\uba38\uc2e0\ub7ec\ub2dd\uc73c\ub85c \uc608\uce21 \ubaa8\ub378 \uad6c\ucd95"),(0,l.kt)("li",{parentName:"ul"},"\ube44\uc988\ub2c8\uc2a4 \ud504\ub85c\uc138\uc2a4\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \ub3c4\uad6c \uac1c\ubc1c"),(0,l.kt)("li",{parentName:"ul"},"cleaning \uc791\uc5c5\uc73c\ub85c \uc774\uc0c1\uce58(outlier) \uc81c\uac70"),(0,l.kt)("li",{parentName:"ul"},"\ube44\uc988\ub2c8\uc2a4\uc5d0 \ub300\ud55c \uae4a\uc740 \uc774\ud574\ub97c \uac00\uc9d0")))),(0,l.kt)("p",null,"Database"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uac04\ub7b5\ud558\uac8c \ub9d0\ud558\uba74 DB\ub294 \ub9ce\uc740 \uc591\uc758 \ub370\uc774\ud130\ub97c \ubcf4\uc720\ud558\ub294 \ucef4\ud4e8\ud130 \uc2dc\uc2a4\ud15c"),(0,l.kt)("li",{parentName:"ul"},"\uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc740 \ud2b9\uc815 \uae30\ub2a5\uc744 \uc81c\uacf5\ud558\uae30 \uc704\ud5e4 DB\uc5d0 \uc758\uc874")),(0,l.kt)("p",null,"Processing"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"clean, aggregate, join\ud558\uae30 \uc704\ud574 \ub370\uc774\ud130 \ucc98\ub9ac"),(0,l.kt)("li",{parentName:"ul"},"\uc5c4\uccad\ub09c \uc591\uc758 \ub370\uc774\ud130 \ucc98\ub9ac",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ubcd1\ub82c \ucc98\ub9ac"),(0,l.kt)("li",{parentName:"ul"},"\ud55c \ucef4\ud4e8\ud130\uc5d0\uc11c \ub370\uc774\ud130 \ucc98\ub9ac -> virtual machine cluster\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubd84\uc0b0\ud558\uc5ec \ub370\uc774\ud130 \ucc98\ub9ac",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc774\ub7f0 \ud234\uc740 \uae30\ubcf8 \uc544\ud0a4\ud14d\ucc98 \ucd94\uc0c1\ud654, \uac04\ub2e8\ud55c API \uc81c\uacf5"),(0,l.kt)("li",{parentName:"ul"},"e.g.",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'df = spark.read.parquet("users.parquet")\noutliers = df.filter(df["age"] > 100)\nprint(outliers.count())\n')))))))),(0,l.kt)("p",null,"Scheduling"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130\uac00 \ud2b9\uc815 \uac04\uaca9\uc5d0 \ub530\ub77c \uc801\uc808\ud55c \uc2dc\uac04\uc5d0 \ud55c \uc7a5\uc18c\uc5d0\uc11c \ub2e4\ub978 \uc7a5\uc18c\ub85c \uc774\ub3d9\ud558\ub294\uc9c0 \ud655\uc778"),(0,l.kt)("li",{parentName:"ul"},"\uacbd\uc6b0\uc5d0 \ub530\ub77c \ucc98\ub9ac \uc791\uc5c5\uc774 \uc62c\ubc14\ub974\uac8c \uc791\ub3d9\ud558\ub824\uba74 \ud2b9\uc815 \uc21c\uc11c\ub85c \uc2e4\ud589\ub418\uc5b4\uc57c \ud568",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc2dc\uac04\uc5d0 \ub9de\uac8c \uc2e4\ud589\ub418\ub3c4\ub85d \ud558\uace0 \uc62c\ubc14\ub978 \uc21c\uc11c\ub85c \uc2e4\ud589\ub418\ub3c4\ub85d \ub9cc\ub4ec"))),(0,l.kt)("li",{parentName:"ul"},"\uc791\uc5c5\uc758 \uc885\uc18d\uc131\uc774 \uc62c\ubc14\ub974\uac8c \ud574\uacb0\ub418\uc5b4\uc57c \ud568")),(0,l.kt)("p",null,"Existing tools"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Databases: MySQL, PostgreSQL"),(0,l.kt)("li",{parentName:"ul"},"Processing: Apache Spark, Apache Hive"),(0,l.kt)("li",{parentName:"ul"},"Scheduling: Apache Airflow, Oozie, cron")),(0,l.kt)("p",null,"Data Pipeline"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"DB\uc640 \uc5f0\uacb0\ud558\uc5ec \ubaa8\ub4e0 \ub370\uc774\ud130 Extract, Transform"),(0,l.kt)("li",{parentName:"ul"},"Spark \uac19\uc740 cluster computing framework\ub97c \uc0ac\uc6a9\ud558\uc5ec analytical DB\uc5d0 Load"),(0,l.kt)("li",{parentName:"ul"},"Airflow\uc640 \uac19\uc740 scheduling framework\ub97c \ud1b5\ud574 \ud2b9\uc815 \uc21c\uc11c\ub85c \uc2e4\ud589\ub418\ub3c4\ub85d scheduling"),(0,l.kt)("li",{parentName:"ul"},"source\uac00 \uc678\ubd80 API \ub610\ub294 \uae30\ud0c0 \ud30c\uc77c \ud615\uc2dd\uc77c \uc218\ub3c4 \uc788\uc74c")),(0,l.kt)("p",null,"Data processing in the cloud"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uacfc\uac70\uc5d0\ub294 \uc790\uccb4 \ub370\uc774\ud130 \uc13c\ud130\ub97c \uc124\ub9bd\ud558\uc5ec \uc11c\ubc84 \ub799\uc744 \uc0ac\uc6a9",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc804\uae30 \uc694\uae08, \uc720\uc9c0\uad00\ub9ac \ube44\uc6a9"),(0,l.kt)("li",{parentName:"ul"},"\ud53c\ud06c \ud0c0\uc784\uc5d0 \ucda9\ubd84\ud55c \ucc98\ub9ac \ub2a5\ub825 \ud544\uc694 -> \uc0ac\uc6a9\uc774 \uc5c6\uc744 \ub54c\ub294 \ucc98\ub9ac \ub2a5\ub825\uc774 \uadf8\ub300\ub85c \ub0a8\uc544\uc788\uc74c -> \ub9ac\uc18c\uc2a4 \ub0ad\ube44"),(0,l.kt)("li",{parentName:"ul"},"\uc7ac\ub09c\uc744 \ub300\ube44\ud574 \ub370\uc774\ud130\ub97c \ub2e4\ub978 \uc9c0\ub9ac\uc801 \uc704\uce58\uc5d0 \ubcf5\uc81c \ud544\uc694"))),(0,l.kt)("li",{parentName:"ul"},"\ud074\ub77c\uc6b0\ub4dc",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub9ac\uc18c\uc2a4\ub97c \ud544\uc694\ud560 \ub54c \uc0ac\uc6a9"),(0,l.kt)("li",{parentName:"ul"},"\ube44\uc6a9 \ucd5c\uc801\ud654"),(0,l.kt)("li",{parentName:"ul"},"DB \uc548\uc815\uc131 -> \uc7ac\ub09c \uac19\uc740 \ucd5c\uc545\uc758 \uc0c1\ud669\uc5d0 \ub300\ube44")))),(0,l.kt)("p",null,"AWS, Azure, GCP"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"2017 AWS \uc911\ub2e8 \ubc1c\uc0dd"),(0,l.kt)("li",{parentName:"ul"},"2018 \uae30\uc900 \uc810\uc720\uc728: AWS > Azure > GCP")),(0,l.kt)("p",null,"Storage"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ubaa8\ub4e0 \uc720\ud615 \ud30c\uc77c \ud074\ub77c\uc6b0\ub4dc\uc5d0 \uc5c5\ub85c\ub4dc"),(0,l.kt)("li",{parentName:"ul"},"\uc77c\ubc18\uc801\uc73c\ub85c \ub9e4\uc6b0 \uc800\ub834"),(0,l.kt)("li",{parentName:"ul"},"\ud30c\uc77c \uc548\uc815\uc801\uc73c\ub85c \uc800\uc7a5"),(0,l.kt)("li",{parentName:"ul"},"AWS S3, Azure Blob Storage, Google Cloud Storage")),(0,l.kt)("p",null,"Computation"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ud074\ub77c\uc6b0\ub4dc\uc5d0\uc11c \uacc4\uc0b0 \uc218\ud589"),(0,l.kt)("li",{parentName:"ul"},"\uac00\uc0c1\uba38\uc2e0\uc744 \uc6d0\ud558\ub294\ub300\ub85c \uc0ac\uc6a9 -> \ud544\uc694\uc5d0 \ub530\ub77c \uc720\uc5f0\ud558\uac8c \uc2dc\uc791, \uc911\uc9c0",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"e.g. \uc6f9 \uc11c\ubc84 \ud638\uc2a4\ud305"))),(0,l.kt)("li",{parentName:"ul"},"AWS EC2, Azure Virtual Machines, Google Compute Engine")),(0,l.kt)("p",null,"Database"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"DB \ud638\uc2a4\ud305"),(0,l.kt)("li",{parentName:"ul"},"AWS RDS, Azure SQL Database, Google Cloud SQL")),(0,l.kt)("h2",{id:"data-engineering-toolbox"},"Data engineering toolbox"),(0,l.kt)("p",null,"Database \uc815\uc758"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130 \ubcf4\uc720"),(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130 \uad6c\uc131"),(0,l.kt)("li",{parentName:"ul"},"DBMS\ub97c \ud1b5\ud574 \ub418\ucc3e\uc544\uc624\uac70\ub098 \uac80\uc0c9\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub428 ")),(0,l.kt)("p",null,"DB\uc640 File system \ucc28\uc774"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"DB",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub9e4\uc6b0 \uc870\uc9c1\ud654\ub418\uc5b4 \uc788\uc74c"),(0,l.kt)("li",{parentName:"ul"},"\uac80\uc0c9, \ubcf5\uc81c \ub4f1\uacfc \uac19\uc740 \ubcf5\uc7a1\ud55c \uc791\uc5c5\ub4e4\uc744 \ucd94\uc0c1\ud654"))),(0,l.kt)("li",{parentName:"ul"},"File system",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub35c \uc870\uc9c1\ud654\ub418\uc5b4 \uc788\uc74c"),(0,l.kt)("li",{parentName:"ul"},"\uc704\uc640 \uac19\uc740 \uae30\ub2a5\ub4e4\uc774 \uac04\ub2e8\ud558\uac70\ub098 \ub35c\ud568")))),(0,l.kt)("p",null,"Structured and unstructured data"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Structured: database schema",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"RDBMS\uc758 \ud14c\uc774\ube14 \ud615\uc2dd \ub370\uc774\ud130"))),(0,l.kt)("li",{parentName:"ul"},"Semi-structured",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"JSON"))),(0,l.kt)("li",{parentName:"ul"},"Unstructured: shemaless, \ud30c\uc77c\uacfc \ub354 \ube44\uc2b7\ud568",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ube44\ub514\uc624, \uc0ac\uc9c4")))),(0,l.kt)("p",null,"SQL and NoSQL"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"SQL",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Tables"),(0,l.kt)("li",{parentName:"ul"},"Database schema: \ud14c\uc774\ube14 \uac04\uc758 \uad00\uacc4, \uc18d\uc131 \uc815\uc758"),(0,l.kt)("li",{parentName:"ul"},"RDBMS(Relational DataBase Management System)"),(0,l.kt)("li",{parentName:"ul"},"Mysql, PostgreSQL"))),(0,l.kt)("li",{parentName:"ul"},"NoSQL",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Non-relational database"),(0,l.kt)("li",{parentName:"ul"},"NoSQL DB\uc5d0\ub294 \uc5ec\ub7ec\uac00\uc9c0 \uc720\ud615\uc774 \uc788\uc74c",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"unstructured data\ub9cc \uc5f0\uacb0\ub418\ub294 \uac83\uc774 \uc544\ub2d8 -> structured data\ub3c4 \uc5f0\uacb0\ub420 \uc218 \uc788\uc74c"))),(0,l.kt)("li",{parentName:"ul"},"Key-value \uc800\uc7a5(e.g. caching, \ubd84\uc0b0 \uad6c\uc870)"),(0,l.kt)("li",{parentName:"ul"},"Document DB(e.g. JSON object -> structured or unstructured object)"),(0,l.kt)("li",{parentName:"ul"},"Redis, MongoDB")))),(0,l.kt)("p",null,"database schema"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"DB\uc758 \uad6c\uc870\uc640 \uad00\uacc4 \uc124\uba85 ")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g. \uc2a4\ud0a4\ub9c8 \ud14c\uc774\ube14 \uc0dd\uc131"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},'-- Create Customer Table\nCREATE TABLE "customer" (\n  "id" SERIAL NOT NULL,\n  "first_name" varchar,\n  "last_name" varchar,\n  PRIMARY KEY ("id")\n);\n\n-- Create Order Table\nCREATE TABLE "Order" (\n  "id" SERIAL NOT NULL,\n  "customer_id" integer REFERENCES "Customer",\n  "product_name" varchar,\n  "product_price" integer,\n  PRIMARY KEY ("id")\n);\n')),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"customer_id\ub85c \uc8fc\ubb38\uc744 \uace0\uac1d\uacfc \uc5f0\uacb0 -> foreign key"),(0,l.kt)("li",{parentName:"ul"},"JOIN \ubb38\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud14c\uc774\ube14\uc744 \uc870\uc778\ud558\uc5ec \uc678\ub798 \ud0a4 \ud65c\uc6a9",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},'SELECT * FROM "Customer"\nINNER JOIN "Order"\nON "customer_id" = "Customer"."id";\n')))))),(0,l.kt)("p",null,"Star schema"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"data warehousing\uc5d0\uc11c \uc790\uc8fc \ubcfc \uc218 \uc788\uc74c"),(0,l.kt)("li",{parentName:"ul"},"Redshift\uc640 \uac19\uc740 \ub9ce\uc740 \ubd84\uc11d DB\uc5d0\uc11c \uc2a4\ud0a4\ub9c8\uc5d0 \ub300\ud55c \ucd5c\uc801\ud654 \uc874\uc7ac"),(0,l.kt)("li",{parentName:"ul"},"\uc2a4\ud0c0 \uc2a4\ud0a4\ub9c8\ub294 \uc5ec\ub7ec \ucc28\uc6d0 \ud14c\uc774\ube14\uc744 \ucc38\uc870\ud558\ub294 \ud558\ub098 \uc774\uc0c1\uc758 fact table\ub85c \uad6c\uc131"),(0,l.kt)("li",{parentName:"ul"},"Fact table\uc5d0\ub294 \uc138\uc0c1\uc5d0\uc11c \uc77c\uc5b4\ub098\ub294 \uc77c\ub4e4\uc744 \ud45c\ud604\ud558\ub294 record \ud3ec\ud568\ub418\uc5b4 \uc788\uc74c",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"e.g. orders"))),(0,l.kt)("li",{parentName:"ul"},"Dimension table\uc740 \uc138\uacc4 \uc790\uccb4\uc5d0 \ub300\ud55c \uc815\ubcf4",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"e.g. customer information ")))),(0,l.kt)("p",null,"The database schema"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Complete the SELECT statement\ndata = pd.read_sql("""\nSELECT first_name, last_name FROM "Customer"\nORDER BY last_name, first_name\n""", db_engine)\n\n# Show the first 3 rows of the DataFrame\nprint(data.head(3))\n\n# Show the info of the DataFrame\nprint(data.info())\n')),(0,l.kt)("p",null,"Joining on relations"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Complete the SELECT statement\ndata = pd.read_sql("""\nSELECT * FROM "Customer"\nINNER JOIN "Order"\nON "Order"."customer_id"="Customer"."id"\n""", db_engine)\n\n# Show the id column of data\nprint(data.id)\n')),(0,l.kt)("p",null,"parallel computing"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uac70\uc758 \ubaa8\ub4e0 \ucd5c\uc2e0 \ub370\uc774\ud130 \ucc98\ub9ac \ub3c4\uad6c\uc758 \uae30\ucd08\ub97c \ud615\uc131"),(0,l.kt)("li",{parentName:"ul"},"\ubcd1\ub82c \ucef4\ud4e8\ud305\uc774 \uc911\uc694\ud55c \uc774\uc720",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uba54\ubaa8\ub9ac  ",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uba54\ubaa8\ub9ac\uc5d0 \ubaa8\ub4e0 \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud560 \ud544\uc694 \uc5c6\uc74c"),(0,l.kt)("li",{parentName:"ul"},"dataset\uc744 \ubd84\ud560\ud558\uc5ec \ub2e4\ub978 \ucef4\ud4e8\ud130\uc758 \uba54\ubaa8\ub9ac\uc5d0 \ub85c\ub4dc -> \ucef4\ud4e8\ud130 \ub2f9 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 \ub0ae\ucda4"),(0,l.kt)("li",{parentName:"ul"},"\uac01 \ucef4\ud4e8\ud130\ub294 \uba54\ubaa8\ub9ac \uacf5\uac04\uc774 \uc0c1\ub300\uc801\uc73c\ub85c \uc791\uc74c"),(0,l.kt)("li",{parentName:"ul"},"RAM\uc5d0 \uac00\uae4c\uc6b4 \uba54\ubaa8\ub9ac\uc5d0 \ub4e4\uc5b4\uac08 \uc218 \uc788\uc74c"))),(0,l.kt)("li",{parentName:"ul"},"\ucc98\ub9ac \ub2a5\ub825",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc5ec\ub7ec \uac1c\uc758 \uc791\uc740 \ud558\uc704 \uc791\uc5c5\ub4e4\ub85c \ubd84\ud560 -> \uc5ec\ub7ec \ucef4\ud4e8\ud130\uc5d0 \ubc30\ud3ec",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub110\ub9ac \uc0ac\uc6a9 \uac00\ub2a5, \uc0c1\ub300\uc801\uc73c\ub85c \uc800\ub834"))),(0,l.kt)("li",{parentName:"ul"},"\uac1c\ubcc4\uc801\uc73c\ub85c\ub294 \uc804\uccb4 \uc791\uc5c5\uc744 \ucc98\ub9ac\ud558\ub294\ub370 \uc624\ub79c \uc2dc\uac04\uc774 \uac78\ub9ac\uc9c0\ub9cc \ub354 \uc791\uc740 \ud558\uc704 \uc791\uc5c5\uc5d0\uc11c \ubcd1\ub82c\ub85c \uc791\ub3d9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc804\uccb4 \uc791\uc5c5\uc774 \ub354 \ube60\ub974\uac8c \uc218\ud589\ub428"),(0,l.kt)("li",{parentName:"ul"},"\uc5ec\ub7ec \uac1c\uc758 processing unit\uc744 \uac00\uc9c0\uba74 \ucc98\ub9ac \ub2a5\ub825 \ud5a5\uc0c1"))))),(0,l.kt)("li",{parentName:"ul"},"\ubcd1\ub82c\ucef4\ud4e8\ud305\uc740 \ube44\uc6a9\uc774 \ub4e4 \uc218 \uc788\uc74c",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ud558\uc704 \uc791\uc5c5\uc73c\ub85c \ubd84\ud560, \ud558\uc704 \uc791\uc5c5\uc758 \uacb0\uacfc \ubcd1\ud569 \uacfc\uc815\uc5d0\uc11c communication cost \ubc1c\uc0dd"),(0,l.kt)("li",{parentName:"ul"},"\ucc98\ub9ac \uc694\uad6c\uc0ac\ud56d\uc774 \ub9ce\uc9c0 \uc54a\uac70\ub098 processing unit\uc774 \ub108\ubb34 \uc801\uc740 \uacbd\uc6b0 communication ovearhead\ub294 \ubcd1\ubaa9\ud604\uc0c1(bottleneck)\uc774 \uc77c\uc5b4\ub0a8",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"overhead: \uc5b4\ub5a4 \ucc98\ub9ac\ub97c \ud558\uae30 \uc704\ud574 \ub4e4\uc5b4\uac00\ub294 \uac04\uc811\uc801\uc778 \ucc98\ub9ac \uc2dc\uac04, \uba54\ubaa8\ub9ac \ub4f1"))),(0,l.kt)("li",{parentName:"ul"},"overhead \ub54c\ubb38\uc5d0 \ubd84\ud560\ud560 \ub54c \uc18d\ub3c4\uac00 \uc120\ud615\uc801\uc73c\ub85c \uc99d\uac00\ud558\uc9c0 \uc54a\uc744 \uc218 \uc788\uc74c",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"parallel slowdown")))))),(0,l.kt)("p",null,"multiprocessing.Pool"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"low level\uc5d0\uc11c multiprocessing.Pool")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from multiprocessing import Pool\n\ndef take_mean_age(year_and_group):\n    year, group = year_and_group\n    return pd.DataFrame({"Age": group["Age"].mean()}, index=[year])\n\nwith Pool(4) as p:\n    results = p.map(take_mean_age, athlete_events.groupby("Year")) # mapping -> 4 seperate process\n\nresult_df = pd.concat(results)\n')),(0,l.kt)("p",null,"\uc5ec\ub7ec \ud328\ud0a4\uc9c0\ub294 \uc774\ub7ec\ud55c \ub0ae\uc740 \uc218\uc900\uc758 \ucf54\ub4dc\ub97c \uc791\uc131\ud560 \ud544\uc694\uac00 \uc5c6\ub3c4\ub85d \ucd94\uc0c1\ud654 \uacc4\uce35\uc744 \uc81c\uacf5"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g. dask"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"GROUPBY \uc218\ud589, multiprocessing \uc0ac\uc6a9\ud558\ub294 DataFrame \uac1d\uccb4 \uc81c\uacf5")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Lazy evaluation \uc0ac\uc6a9 -> .compute() \ubd99\uc784")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Using a DataFrame"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},"import dask.dataframe as dd\n\n# Partition dataframe into 4\nathlete_events_dask = dd.from_pandas(athlete_events, npartitions=4)\n\n# Run parallel computations on each partition\n# Calculate the mean Age per Year\nresult_df = athlete_events_dask.groupby('Year').Age.mean().compute()\n")))))),(0,l.kt)("p",null,"From task to subtasks"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"## From task to subtasks\n\n# Function to apply a function over multiple cores\n@print_timing\ndef parallel_apply(apply_func, groups, nb_cores):\n    with Pool(nb_cores) as p:\n        results = p.map(apply_func, groups)\n    return pd.concat(results)\n\n# Parallel apply using 1 core\nparallel_apply(take_mean_age, athlete_events.groupby('Year'), 1)\n\n# Parallel apply using 2 cores\nparallel_apply(take_mean_age, athlete_events.groupby('Year'), 2)\n\n# Parallel apply using 4 cores\nparallel_apply(take_mean_age, athlete_events.groupby('Year'), 4)\n")),(0,l.kt)("p",null,"Hadoop "),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Apache Software Foundation\uc5d0\uc11c \uc720\uc9c0\uad00\ub9ac\ud558\ub294 \uc624\ud508\uc18c\uc2a4 \ud504\ub85c\uc81d\ud2b8"),(0,l.kt)("li",{parentName:"ul"},"HDFS",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ubd84\uc0b0 \ud30c\uc77c \uc2dc\uc2a4\ud15c"),(0,l.kt)("li",{parentName:"ul"},"\ud30c\uc77c \uc2dc\uc2a4\ud15c\uacfc \uc720\uc0ac"),(0,l.kt)("li",{parentName:"ul"},"\ud30c\uc77c\uc774 \ub2e4\ub978 \ucef4\ud4e8\ud130\ub4e4\uc5d0 \uc874\uc7ac"),(0,l.kt)("li",{parentName:"ul"},"\ud655\uc7a5\uc5d0 \uc758\ud55c parallel computing\uc5d0\uc11c\ub294 \ud544\uc218\uc801\uc774\uc5c8\uc74c"),(0,l.kt)("li",{parentName:"ul"},"S3 \uac19\uc740 storage system\uc774 \uc885\uc885 HDFS\ub97c \ub300\uccb4"))),(0,l.kt)("li",{parentName:"ul"},"MapReduce",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub300\uc911\ud654 \ub41c \ucd5c\ucd08\uc758 \ube45\ub370\uc774\ud130 \ucc98\ub9ac \ud328\ub7ec\ub2e4\uc784 \uc911 \ud558\ub098"),(0,l.kt)("li",{parentName:"ul"},"\ud558\uc704 \uc791\uc5c5\uc73c\ub85c \ub098\ub204\uace0 \uc5ec\ub7ec processing unit\uc5d0 workload\uc640 data \ubd84\ubc30 -> computer cluster"),(0,l.kt)("li",{parentName:"ul"},"\uc791\uc5c5\uc744 \uc791\uc131\ud558\uae30 \uc5b4\ub824\uc6c0 -> Hive\ub85c \ud574\uacb0"),(0,l.kt)("li",{parentName:"ul"},"MapReduce \uae30\ubc18 \uc2dc\uc2a4\ud15c\uc740 \uc791\uc5c5 \uac04\uc5d0 \uace0\uac00\uc758 \ub514\uc2a4\ud06c \uc4f0\uae30\uac00 \ud544\uc694 -> MapReduce\uc758 \ud55c\uacc4"),(0,l.kt)("li",{parentName:"ul"},"MapReduce\uc758 \ub514\uc2a4\ud06c \uc4f0\uae30\ub294 \uac01 \ub2e8\uacc4\uac00 \uc774\uc804 \ub2e8\uacc4 \uc704\uc5d0 \uad6c\ucd95\ub418\ub294 interactive\ud55c EDA(Exploratory Data Analysis)\uc5d0\uc11c \uc81c\ud55c\uc801")))),(0,l.kt)("p",null,"Hive"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub294 Hadoop echo system\uc758 \ucd5c\uc0c1\uc704 \uacc4\uce35"),(0,l.kt)("li",{parentName:"ul"},"Hive SQL\uc744 \uc0ac\uc6a9\ud558\uc5ec structured query",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"parallel processing\uc744 \uc704\ud574 structured query \uc0ac\uc6a9"))),(0,l.kt)("li",{parentName:"ul"},"Facebook\uc774 \uac1c\ubc1c\ud588\uc9c0\ub9cc \uc774\uc820 Apache software Fondation\uc5d0\uc11c \ud504\ub85c\uc81d\ud2b8 \uc720\uc9c0"),(0,l.kt)("li",{parentName:"ul"},"\ucc98\uc74c\uc5d0\ub294 MapReduce\ub85c Hive\ub97c \uc2e4\ud589\ud588\uc9c0\ub9cc \uc9c0\uae08\uc740 \ub2e4\ub978 \ub370\uc774\ud130 \ucc98\ub9ac \ub3c4\uad6c\uc640 \ud1b5\ud569\ub428"),(0,l.kt)("li",{parentName:"ul"},"e.g.",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT year, AVG(age)\nFROM views.athlete_events\nGROUP BY year\n")),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc77c\ubc18 sql\uacfc \ub2e4\ub978 \uac83\uc774 \uc5c6\uc5b4 \ubcf4\uc774\uc9c0\ub9cc \ub4a4\uc5d0\uc11c\ub294 cluster\uc5d0\uc11c \uc791\ub3d9\ud560 \uc218 \uc788\ub294 \uc791\uc5c5\uc73c\ub85c \ubcc0\ud658\ub428"),(0,l.kt)("li",{parentName:"ul"},"Hive -> MapReduce -> cluster")))),(0,l.kt)("p",null,"Spark"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"computer cluster\uac04\uc5d0 \ub370\uc774\ud130 \ucc98\ub9ac \uc791\uc5c5\uc744 \ubd84\uc0b0\uc2dc\ud0b4"),(0,l.kt)("li",{parentName:"ul"},"Spark\ub294 \uba54\ubaa8\ub9ac\uc5d0\uc11c \uac00\ub2a5\ud55c \ub9ce\uc740 \ucc98\ub9ac\ub97c \ud558\ub824\uace0 \ud568 -> MapReduce \ud55c\uacc4 \ud574\uacb0"),(0,l.kt)("li",{parentName:"ul"},"UC Berkeley AMPLab\uc5d0\uc11c \uac1c\ubc1c, \ud604\uc7ac\ub294 Apache Software Foundation\uc5d0\uc11c \uc720\uc9c0\uad00\ub9ac")),(0,l.kt)("p",null,"Resilient distributed datasets(RDD)"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uc2a4\ud30c\ud06c\uac00 \uc758\uc874"),(0,l.kt)("li",{parentName:"ul"},"\uc5ec\ub7ec \ub178\ub4dc \uac04\uc758 \ubd84\uc0b0\ub41c \ub370\uc774\ud130\ub97c \uc720\uc9c0\ud558\ub294 \uc790\ub8cc\uad6c\uc870"),(0,l.kt)("li",{parentName:"ul"},"DataFrame\uacfc \ub2e4\ub974\uac8c \uc5f4\uc5d0 \uc774\ub984\uc774 \uc5c6\uc74c -> tuple\uacfc \ube44\uc2b7\ud568"),(0,l.kt)("li",{parentName:"ul"},"Operation",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Transformation: map() or filter()"),(0,l.kt)("li",{parentName:"ul"},"Action: count() or first()")))),(0,l.kt)("p",null,"Pyspark"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Spark\uc5d0 \ub300\ud55c python interface"),(0,l.kt)("li",{parentName:"ul"},"DataFrame abstraction \ud638\uc2a4\ud2b8",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"pandas\uc758 DataFrame\uacfc \ube44\uc2b7\ud558\uac8c \uc0ac\uc6a9"))),(0,l.kt)("li",{parentName:"ul"},"\ubcf5\uc7a1\ud55c parallel computing operation \ucc98\ub9ac"),(0,l.kt)("li",{parentName:"ul"},"e.g.",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Load the dataset into athlete_events_spark first\n(athlete_events_spark\n  .groupBy('Year')\n  .mean('Age')\n  .show())\n")))),(0,l.kt)("p",null,"PySpark groupby"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Print the type of athlete_events_spark\nprint(type(athlete_events_spark))\n\n# Print the schema of athlete_events_spark\nprint(athlete_events_spark.printSchema())\n\n# Group by the Year, and find the mean Age\nprint(athlete_events_spark.groupBy('Year').mean('Age'))\n\n# Group by the Year, and find the mean Age\nprint(athlete_events_spark.groupBy('Year').mean('Age').show())\n")),(0,l.kt)("p",null,"An example pipeline"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"csv \ucd94\ucd9c, spark\ub85c clean, sql load"),(0,l.kt)("li",{parentName:"ul"},"How to schedule?",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc218\ub3d9\uc73c\ub85c \uc791\uc5c5 \uc2e4\ud589"),(0,l.kt)("li",{parentName:"ul"},"Linux cron \uac19\uc740 scheduling tool \uc0ac\uc6a9"))),(0,l.kt)("li",{parentName:"ul"},"CSV \ud30c\uc77c \uc791\uc5c5, API\ub85c \ub370\uc774\ud130\ub97c \uac00\uc838\uc640\uc11c clean\ud558\ub294 \uc791\uc5c5, \ub370\uc774\ud130\ub97c join\ud558\ub294 \uc791\uc5c5",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc791\uc5c5\uc5d0 \ub300\ud55c \uc758\uc874\uc131\uc774 \uc0dd\uae40 -> DAG(Directed Acyclic Graph)\ub85c \uc758\uc874\uc131 \uc2dc\uac01\ud654")))),(0,l.kt)("p",null,"DAG(Directed Acyclic Graph)"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"directed edge\ub85c \uc5f0\uacb0\ub41c node\ub4e4\uc758 \uc9d1\ud569"),(0,l.kt)("li",{parentName:"ul"},"cycle\uc774 \uc5c6\ub294 graph",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ud2b9\uc815 \ub178\ub4dc\uac00 \ub450\ubc88 \uc774\uc0c1 \ud45c\uc2dcX")))),(0,l.kt)("p",null,"\uc704\uc758 \uc791\uc5c5\uc5d0 \ub300\ud55c tool"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Linux\uc758 cron")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Spotify\uc758 Luigi"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ubcf5\uc7a1\ud55c \ud30c\uc774\ud504\ub77c\uc778\uc5d0 \ub300\ud574 DAG\ub97c \uc815\uc758\ud560 \uc218 \uc788\uc74c"))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Apache Airflow"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\uc0ac\uc2e4\uc0c1 workflow scheduling framework")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Airbnb\uac00 workflow \uad00\ub9ac\ub97c \uc704\ud574 \ub9cc\ub4ec")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"2015 \uc624\ud508 \uc18c\uc2a4\ub85c \uacf5\uac1c, 2016\ub144 Apache Software Foundation\uc5d0 \uac00\uc785")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\ud30c\uc774\uc36c\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubcf5\uc7a1\ud55c \ud30c\uc774\ud504\ub77c\uc778\uc744 \uad6c\ucd95\ud558\ub294 DAG\ub97c \ub9cc\ub4e4\uace0 \ud14c\uc2a4\ud2b8\ud560 \uc218 \uc788\uc74c")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g."),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Create the DAG object\ndag = DAG(dag_id="example_dag", ..., schedule_interval="0 * * * *")\n\n# Define operations\nstart_cluster = StartClusterOperator(task_id="start_cluster", dag=dag)\ningest_customer_data = SparkJobOperator(task_id="ingest_customer_data", dag=dag)\ningest_product_data = SparkJobOperator(task_id="ingest_product_data", dag=dag)\nenrich_customer_data = PythonOperator(task_id="enrich_customer_data", ..., dag=dag)\n\n# Set up dependency flow\nstart_culster.set_downstream(ingest_customer_data)\ningest_customer_data.set_downstream(enrich_customer_data)\ningest_product_data.set_downstream(enrich_customer_data)\n')))))),(0,l.kt)("p",null,"Airflow DAGs"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Create the DAG object\ndag = DAG(dag_id="car_factory_simulation",\n          default_args={"owner": "airflow","start_date": airflow.utils.dates.days_ago(2)},\n          schedule_interval="0 * * * *")\n\n# Task definitions\nassemble_frame = BashOperator(task_id="assemble_frame", bash_command=\'echo "Assembling frame"\', dag=dag)\nplace_tires = BashOperator(task_id="place_tires", bash_command=\'echo "Placing tires"\', dag=dag)\nassemble_body = BashOperator(task_id="assemble_body", bash_command=\'echo "Assembling body"\', dag=dag)\napply_paint = BashOperator(task_id="apply_paint", bash_command=\'echo "Applying paint"\', dag=dag)\n\n# Complete the downstream flow\nassemble_frame.set_downstream(place_tires)\nassemble_frame.set_downstream(assemble_body)\nassemble_body.set_downstream(apply_paint)\n')),(0,l.kt)("h2",{id:"extract-transform-and-loadetl"},"Extract, Transform and Load(ETL)"),(0,l.kt)("p",null,"Extracting data"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130 \ucc98\ub9ac\uc5d0 \uc801\ud569\ud558\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\ub97c S3 \uac19\uc740 \uc11c\ube44\uc2a4 \ub610\ub294 DB\uc5d0\uc11c \uba54\ubaa8\ub9ac\ub85c \ucd94\ucd9c"),(0,l.kt)("li",{parentName:"ul"},"Plain text file"),(0,l.kt)("li",{parentName:"ul"},"Flat file",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uac01 row\uac00 record, \uac01 column\uc774 record atrribute"),(0,l.kt)("li",{parentName:"ul"},"tarbular format"),(0,l.kt)("li",{parentName:"ul"},"csv, tsv"))),(0,l.kt)("li",{parentName:"ul"},"JSON(JavaScript Object Notation)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Semi-structured"),(0,l.kt)("li",{parentName:"ul"},"Atomic",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"number"),(0,l.kt)("li",{parentName:"ul"},"string"),(0,l.kt)("li",{parentName:"ul"},"boolean"),(0,l.kt)("li",{parentName:"ul"},"null"))),(0,l.kt)("li",{parentName:"ul"},"Composite",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"array"),(0,l.kt)("li",{parentName:"ul"},"object"))),(0,l.kt)("li",{parentName:"ul"},"\ud30c\uc774\uc36c dict\uc640 mappging -> ",(0,l.kt)("inlineCode",{parentName:"li"},"import json"))))),(0,l.kt)("p",null,"Data on the web"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"request, response")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g."),(0,l.kt)("ol",{parentName:"li"},(0,l.kt)("li",{parentName:"ol"},"Browse to Google"),(0,l.kt)("li",{parentName:"ol"},"Request to Google Server"),(0,l.kt)("li",{parentName:"ol"},"Google responds with web page"))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\uc0ac\ub78c\uc774 \uc77d\uae30 \ud798\ub4e0 \uc6f9 \ud398\uc774\uc9c0\ub3c4 \uc874\uc7ac"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"JSON format")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\uc11c\ubc84 API(Application Programming Interface)"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g."),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"twitter\ub294 JSON \ud615\uc2dd\uc73c\ub85c \ud2b8\uc717\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\ub294 API \ud638\uc2a4\ud305")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Hackernews API"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nresponse = requests.get("https://hacker-news.firebaseio.com/v0/item/16222426.json")\nprint(response.json())\n')))))))))),(0,l.kt)("p",null,"Database"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uc77c\ubc18\uc801\uc778 \ub370\uc774\ud130 \ucd94\ucd9c \ubc29\ubc95 -> \uae30\uc874 application DB\uc5d0\uc11c \ucd94\ucd9c"),(0,l.kt)("li",{parentName:"ul"},"\ub300\ubd80\ubd84\uc758 application\uc5d0\ub294 \ub370\uc774\ud130\ub97c \ubc31\uc5c5, \uc720\uc9c0\ud558\uae30 \uc704\ud574 DB\uac00 \ud544\uc694"),(0,l.kt)("li",{parentName:"ul"},"Applications databases",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"application\uc774 \uc0ac\uc6a9\ud558\ub294 DB\ub294 \uc77c\ubc18\uc801\uc73c\ub85c \ub9ce\uc740 Transaction \uac00\uc9c0\ub3c4\ub85d \ucd5c\uc801\ud654 \ub418\uc5b4\uc788\uc74c"),(0,l.kt)("li",{parentName:"ul"},"DB\uc5d0\uc11c row \ub610\ub294 record\ub97c \ubcc0\uacbd\ud558\uac70\ub098 \uc0bd\uc785"),(0,l.kt)("li",{parentName:"ul"},"OLTP(Online transaction processing)"),(0,l.kt)("li",{parentName:"ul"},"row-oriented, \uc2dc\uc2a4\ud15c\uc774 \ud589\ubcc4\ub85c \ub370\uc774\ud130\ub97c \ucd94\uac00"))),(0,l.kt)("li",{parentName:"ul"},"Analytical databases",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ubd84\uc11d\uc5d0 \ucd5c\uc801\ud654 \ub41c DB"),(0,l.kt)("li",{parentName:"ul"},"OLAP(Online Analyticall processing)"),(0,l.kt)("li",{parentName:"ul"},"Colum-oriented")))),(0,l.kt)("p",null,"Extraction from database"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Connection string/URI"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"DB\uc5d0 \uc5f0\uacb0\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\ub294 \ubb38\uc790\uc5f4 "),(0,l.kt)("li",{parentName:"ul"},"e.g. PostgreSQL",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"postgresql://[user[:password]@][host][:port]")))))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Python"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre"},'import sqlalchemy\nimport pandas as pd\n\nconnection_uri = "postgresql://repl:password@localhost:5432/pagila"\ndb_engine = sqlalchemy.create_engine(connection_uri)\n\npd.real_sql("SELECT * FROM customer", db_engine)\n')))),(0,l.kt)("p",null,"Fetch from an API"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\n# Fetch the Hackernews post\nresp = requests.get("https://hacker-news.firebaseio.com/v0/item/16222426.json")\n\n# Print the response parsed as JSON\nprint(resp.json())\n\n# Assign the score of the test to post_score\npost_score = resp.json()["score"]\nprint(post_score)\n')),(0,l.kt)("p",null,"Read from a database"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Function to extract table to a pandas DataFrame\ndef extract_table_to_pandas(tablename, db_engine):\n    query = \"SELECT * FROM {}\".format(tablename)\n    return pd.read_sql(query, db_engine)\n\n# Connect to the database using the connection URI\nconnection_uri = \"postgresql://repl:password@localhost:5432/pagila\" \ndb_engine = sqlalchemy.create_engine(connection_uri)\n\n# Extract the film table into a pandas DataFrame\nextract_table_to_pandas('film', db_engine)\n\n# Extract the customer table into a pandas DataFrame\nextract_table_to_pandas('customer', db_engine)\n")),(0,l.kt)("p",null,"\uc5b4\ub5a4 \uc885\ub958\uc758 \ubcc0\ud658\uc744 \uc218\ud589\ud574\uc57c \ud558\ub294\uac00"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\uc18d\uc131\uc744 \uc120\ud0dd ")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\ucf54\ub4dc \uac12 \ubc88\uc5ed")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\ub370\uc774\ud130 \uc720\ud6a8\uc131 \uac80\uc0ac")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\ub2e8\uc77c \uc5f4\uc744 \uc5ec\ub7ec \uc5f4\ub85c split"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g. \uc774\uba54\uc77c\uc744 \uc544\uc774\ub514\uc640 \ub3c4\uba54\uc778\uc73c\ub85c \ubd84\ub9ac"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},"customer_df # Pandas DataFrame with customer data\n\n# Split email column into 2 columns on the '@' symbol\nsplit_email = customer_df.email.str.split(\"@\", expand=True)\n\n# Create 2 new columns using the resulting DataFrame\ncustomer_df = customer_df.assign(\n  username=split_email[0],\n  domail=split_email[1],\n)\n"))))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\uc5ec\ub7ec source\uc5d0\uc11c join"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"e.g. Pyspark"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'customer_df # PySpark DataFrame with customer data\nratings_df # PySpark DataFrame with ratings data\n\n# Groupby ratings\nratings_per_customer = ratings_df.groupBy("customer_id").mean("rating")\n\n# Join on customer ID\ncustomer_df.join(\n  ratings_per_customer,\n  customer_df.customer_id==ratings_per_customer.customer_id\n)\n')))))),(0,l.kt)("p",null,"Transforming in PySpark"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"load\uac00 \uc801\uc73c\uba74 pandas\ub97c \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc74c")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"PySpark\ub97c \uc0ac\uc6a9\ud558\uba74 Extract \ub2e8\uacc4\uc5d0\uc11c table\uc744 Spark\uc5d0 load"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import pyspark.sql\n\nspark = pyspark.sql.SparkSession.builder.getOrCreate()\nspark.read.jdbc("jdbc:postgresql://localhost:5432/pagila",\n                "customer",\n                properties={"user":"repl","password":"password"})\n')),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"JDBC\ub294 Spark\uac00 \uc5ec\ub7ec RDBMS\uc5d0 \uc5f0\uacb0\ud558\ub294\ub370 \ub3c4\uc640\uc8fc\ub294 \uc18c\ud504\ud2b8\uc6e8\uc5b4")))),(0,l.kt)("p",null,"Splitting"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Get the rental rate column as a string\nrental_rate_str = film_df.rental_rate.astype(str)\n\n# Split up and expand the column\nrental_rate_expanded = rental_rate_str.str.split('.', expand=True)\n\n# Assign the columns to film_df\nfilm_df = film_df.assign(\n    rental_rate_dollar=rental_rate_expanded[0],\n    rental_rate_cents=rental_rate_expanded[1],\n)\n")),(0,l.kt)("p",null,"Joining"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"# Use groupBy and mean to aggregate the column\nratings_per_film_df = rating_df.groupBy('film_id').mean('rating')\n\n# Join the tables using the film_id column\nfilm_df_with_ratings = film_df.join(\n    ratings_per_film_df,\n    film_df.film_id==ratings_per_film_df.film_id\n)\n\n# Show the 5 first results\nprint(film_df_with_ratings.show(5))\n")),(0,l.kt)("p",null,"Analytics or applications databases"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Analytics",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ubcf5\uc7a1\ud55c \uc9d1\uacc4 \ucffc\ub9ac\ub294 \ubd84\uc11d DB\uc5d0\uc11c \uc790\uc8fc \uc2e4\ud589 -> \ucd5c\uc801\ud654 \ud544\uc694"),(0,l.kt)("li",{parentName:"ul"},"OLAP\uc704\ud574 \ucd5c\uc801\ud654"),(0,l.kt)("li",{parentName:"ul"},"Column-oriented",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"column \ub2f9 \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud558\uba74 \ud2b9\uc815 \uc5f4\uc744 loop\uc2dc\ucf1c query\ud558\ub294 \uac83\uc774 \ub354 \ube60\ub984"),(0,l.kt)("li",{parentName:"ul"},"parallelization\uc5d0 \ub354 \uc801\ud569"))))),(0,l.kt)("li",{parentName:"ul"},"Application",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ucd08\ub2f9 transaction\uc774 \ub9ce\uc74c -> \ucd5c\uc801\ud654 \ud544\uc694"),(0,l.kt)("li",{parentName:"ul"},"OLTP\uc704\ud574 \ucd5c\uc801\ud654"),(0,l.kt)("li",{parentName:"ul"},"Row-oriented",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"record \ub2f9 \ub370\uc774\ud130\ub97c \uc800\uc7a5 -> \uc18c\uaddc\ubaa8 transaction\uc5d0\uc11c \uc0c8 row\ub97c \uc27d\uac8c \ucd94\uac00")))))),(0,l.kt)("p",null,"MPP DB(Massively Parallel Processing Database)"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"ETL \ud504\ub85c\uc138\uc2a4\uac00 \ub05d\ub0a0 \ub54c \ub300\uc0c1\uc774 \ub418\ub294 DB \uc720\ud615"),(0,l.kt)("li",{parentName:"ul"},"\ubd84\uc0b0 \ubc29\uc2dd\uc73c\ub85c \uc2e4\ud589\ub418\ub294 \ubd84\uc11d\uc5d0 \ucd5c\uc801\ud654 \ub41c column-oriented DB"),(0,l.kt)("li",{parentName:"ul"},"Query\ub294 \ub2e8\uc77c \ucef4\ud4e8\ud305 \ub178\ub4dc\uc5d0\uc11c \uc2e4\ud589\ub418\ub294 \uac83\uc774 \uc544\ub2c8\ub77c \ud558\uc704 \uc791\uc5c5\uc73c\ub85c \ubd84\ud560\ub418\uc5b4 \uc5ec\ub7ec \ub178\ub4dc\uc5d0 \ubd84\uc0b0"),(0,l.kt)("li",{parentName:"ul"},"Amazon Redshift, Azure SQL Data Warehouse, Google BigQuery"),(0,l.kt)("li",{parentName:"ul"},"\uc77c\ubc18\uc801\uc73c\ub85c column-oriented format\uc744 \uc0ac\uc6a9\ud558\ub294 \ud30c\uc77c\uc5d0\uc11c \uc798 load")),(0,l.kt)("p",null,"Redshift"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"S3\uc5d0 \ud30c\uc77c\uc744 \uc4f0\uace0 Redshift\uc5d0 \ubcf5\uc0ac query\ub97c \ubcf4\ub0c4"),(0,l.kt)("li",{parentName:"ul"},"e.g.",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Pandas .to_parquet() method\ndf.to_parquet("./s3://path/to/bucket/customer.parquet")\n# PySpark .write.parquet() method\ndf.write.parquet("./s3://path/to/bucket/customer.parquet")\n')),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"PostgreSQL connection URI\ub97c \uc0ac\uc6a9\ud558\uc5ec Redshift\uc5d0 \uc5f0\uacb0, S3\uc758 \ub370\uc774\ud130\ub97c Redshift\ub85c \ubcf5\uc0ac")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY customer\nFROM 's3://path/to/bucket/customer.parquet'\nFORMAT as parquet\n")))),(0,l.kt)("p",null,"Load to PostgreSQL"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"pandas.to_sql()"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},'# Transformation on data\nrecommendations = transform_find_recommendations(ratings_df)\n\n# Load into PostgreSQL database\nrecommendations.to_sql("recommendations",\n                       db_engine,\n                       schema="store",\n                       if_exitsts="replace")\n')))),(0,l.kt)("p",null,"Writing to a file"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Write the pandas DataFrame to parquet\nfilm_pdf.to_parquet("films_pdf.parquet")\n\n# Write the PySpark DataFrame to parquet\nfilm_sdf.write.parquet("films_sdf.parquet")\n')),(0,l.kt)("p",null,"Load into Postgres"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Finish the connection URI\nconnection_uri = "postgresql://repl:password@localhost:5432/dwh"\ndb_engine_dwh = sqlalchemy.create_engine(connection_uri)\n\n# Transformation step, join with recommendations data\nfilm_pdf_joined = film_pdf.join(recommendations)\n\n# Finish the .to_sql() call to write to store.film\nfilm_pdf_joined.to_sql("film", db_engine_dwh, schema="store", if_exists="replace")\n\n# Run the query to fetch the data\npd.read_sql("SELECT film_id, recommended_film_ids FROM store.film", db_engine_dwh)\n')),(0,l.kt)("p",null,"The ETL function"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"ETL \ub3d9\uc791\uc744 ",(0,l.kt)("inlineCode",{parentName:"p"},"elt()")," \ud568\uc218\ub85c \ucea1\uc290\ud654"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# PostgreSQL table\uc744 pandas DataFrame\uc73c\ub85c extract\ud558\ub294 \ud568\uc218\ndef extract_table_to_dfd(tablename, db_engine):\n  return pd.read_sql("SELECT * FROM {}".format(tablename), db_engine)\n\n# \ubd84\uc11d\uc5d0 \ub354 \uc801\ud569\ud55c \ud615\uc2dd\uc73c\ub85c transform\ndef split_columns_transform(df, column, pat, suffixes):\n  # Converts column into str and splits it on pat...\n\n# \ubcc0\ud658\ub41c \ub370\uc774\ud130\ub97c PostgreSQL DB\uc5d0 load\ndef load_df_into_dwh(film_df, tablename, schema, db_engine):\n  return pd.to_sql(tablename, db_engine, schema=schema, if_exists="replace")\n\ndb_engines = { ... } # Needs to be configured\ndef etl():\n  # Extract\n  film_df = extract_table_to_df("film", db_engines["store"])\n  # Transform\n  film_df = split_columns_transform(film_df, "renntal_rate", ".", ["_dollar", "_cents"])\n  # Load\n  load_df_into_dwh(film_df, "film", "store", db_engines["dwh"])\n')))),(0,l.kt)("p",null,"Airflow"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"\ud2b9\uc815 \uc2dc\uac04\uc5d0 \uc2e4\ud589\ub418\ub3c4\ub85d \ud568")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"python\uc73c\ub85c \uc791\uc131\ub41c workflow scheduler")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Python \uac1d\uccb4\uc5d0\uc11c DAG \uc0ac\uc6a9")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"DAG task \uc0ac\uc774\uc5d0 \uc758\uc874\uc131 \uad00\uacc4\uac00 \uc788\uc744 \uc218 \uc788\uae30\uc5d0 workflow\ub97c \uad00\ub9ac\ud558\ub294 \ub370 \uc644\ubcbd")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"operator\ub294 \uc791\uc5c5\ub2e8\uc704\ub97c \ub098\ud0c0\ub0c4"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\ub2e4\uc591\ud55c \uc885\ub958\uac00 \uc788\uc73c\uba70 custom operator\ub3c4 \uc4f8 \uc218 \uc788\uc74c"))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Scheduling with DAGs in Airflow"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"DAG \uac1d\uccb4 \ub9cc\ub4e4\uae30")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'frorm airflow.models import DAG\n\ndag = DAG(dag_id="sample",\n          ...,\n          schedule_interval="0 0 * * *") # DAG\ub97c \uc2e4\ud589\ud574\uc57c \ud558\ub294 \uc2dc\uae30\ub97c \uc815\uc758\n')),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc77c\ubc18\uc801\uc73c\ub85c cron \ud45c\ud604\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2e4\ud589 \uac04\uaca9\uc744 \uc815\uc758",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"minute(0~59), hour(0~23), day of the month(1~31), month(1~12), day of the week(0~6)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"e.g. 0 * * * * -> \ub9e4 \uc2dc\uac04 0\ubd84"))))))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"The DAG definition file"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from airflow.models import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\ndag = DAG(dag_id="etl_pipeline",\n          schedule_interval="0 0 * * *")\n\netl_task = PythonOperator(task_id="etl_task",\n                          python_callable=etl,\n                          dag=dag)\n\netl_task.set_upstream(wait_for_this_task)\n')),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"etl_dag.py"),"\uc744 ",(0,l.kt)("inlineCode",{parentName:"li"},"~/airflow/dags/"),"\uc5d0 \uc800\uc7a5")))),(0,l.kt)("p",null,"Defining a DAG"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Define the ETL function\ndef etl():\n    film_df = extract_film_to_pandas()\n    film_df = transform_rental_rate(film_df)\n    load_dataframe_to_film(film_df)\n\n# Define the ETL task using PythonOperator\netl_task = PythonOperator(task_id='etl_film',\n                          python_callable=etl,\n                          dag=dag)\n\n# Set the upstream to wait_for_table and sample run etl()\netl_task.set_upstream(wait_for_table)\netl()\n")),(0,l.kt)("h2",{id:"case-study-datacamp"},"Case Study: DataCamp"),(0,l.kt)("p",null,"Ratings at DataCamp"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ud55c \uc7a5\uc774 \ub05d\ub098\uba74 \uc644\ub8cc \ud6c4 \ud3c9\uac00"),(0,l.kt)("li",{parentName:"ul"},"\ud2b9\uc815 \uacfc\uc815\uc744 \ud3c9\uac00\ud558\ub294 \ubc29\ubc95\uc744 \ucd94\uc815 -> \ucd94\ucc9c \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uc0ac\uc6a9\ud558\uae30 \uc801\ud569"),(0,l.kt)("li",{parentName:"ul"},"\ub4f1\uae09 \ub370\uc774\ud130\ub97c clean \uc791\uc5c5 \ud6c4 \uac01 \uc0ac\uc6a9\uc790\uc5d0\uac8c \uad8c\uc7a5\ud558\ub294 \uc0c1\uc704 \uacfc\uc815 \uacc4\uc0b0"),(0,l.kt)("li",{parentName:"ul"},"\ub9e4\uc77c \ub2e4\uc2dc \uacc4\uc0b0 -> dashboard\uc5d0 \uacfc\uc815 \ud45c\uc2dc")),(0,l.kt)("p",null,"ETL process"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"extract rating data",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"datacapmp_application DB\uc758 \ub450 SQL table\uc5d0\uc11c extract \uc218\ud589 -> PostgreSQL"))),(0,l.kt)("li",{parentName:"ul"},"\uc720\uc6a9\ud55c recommendation\uc744 \uc5bb\uae30 \uc704\ud55c transform",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"clean, rating table\uc5d0\uc11c recommendation\uc744 \uacc4\uc0b0\ud558\ub294 \uc54c\uace0\ub9ac\uc998"))),(0,l.kt)("li",{parentName:"ul"},"load application database ",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"data warehouse DB\uc5d0 load"))),(0,l.kt)("li",{parentName:"ul"},"data scientist\ub294 recommendation\uc744 \uc81c\uacf5"),(0,l.kt)("li",{parentName:"ul"},"data engineer\ub294 schedule\uc5d0 \ub9de\uac8c recommendation\uc744 \uc5c5\ub370\uc78d\ud2b8\ud558\ub294 \uc548\uc815\uc801\uc778 \uc2dc\uc2a4\ud15c \uad6c\ucd95")),(0,l.kt)("p",null,"Table"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Course",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"course_id(foreign key), title, description, programming_language"))),(0,l.kt)("li",{parentName:"ul"},"Rating",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"user_id(identifier), course_id, rating")))),(0,l.kt)("p",null,"Querying the table"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Complete the connection URI\nconnection_uri = "postgresql://repl:password@localhost:5432/datacamp_application" \ndb_engine = sqlalchemy.create_engine(connection_uri)\n\n# Get user with id 4387\nuser1 = pd.read_sql("SELECT * FROM rating WHERE user_id=4387", db_engine)\n\n# Get user with id 18163\nuser2 = pd.read_sql("SELECT * FROM rating WHERE user_id=18163", db_engine)\n\n# Get user with id 8770\nuser3 = pd.read_sql("SELECT * FROM rating WHERE user_id=8770", db_engine)\n\n# Use the helper function to compare the 3 users\nprint_user_comparison(user1, user2, user3)\n')),(0,l.kt)("p",null,"Average rating per course"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Complete the transformation function\ndef transform_avg_rating(rating_data):\n    # Group by course_id and extract average rating per course\n    avg_rating = rating_data.groupby('course_id').rating.mean()\n    # Return sorted average ratings per course\n    sort_rating = avg_rating.sort_values(ascending=False).reset_index()\n    return sort_rating\n\n# Extract the rating data into a DataFrame    \nrating_data = extract_rating_data(db_engines)\n\n# Use transform_avg_rating on the extracted data and print results\navg_rating_data = transform_avg_rating(rating_data)\nprint(avg_rating_data) \n")),(0,l.kt)("p",null,"The recommendations table"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"user_id, course_id, rating prediction",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"rating prediction: \ub4f1\uae09 \uc608\uce21\uc744 \ud1b5\ud574 \uc0ac\uc6a9\uc790\uac00 \ucf54\uc2a4\ub97c \uc218\uac15\ud558\uae30 \uc804\uc5d0 \ub4f1\uae09\uc744 \ucd94\uc815"))),(0,l.kt)("li",{parentName:"ul"},"triplet\uc740 rating table\uc5d0\uc11c \uac01 unique\ud55c user id\uc5d0 \ub300\ud55c \ucd94\ucc9c \ucf54\uc2a4 top 3\ub85c \uad6c\uc131",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"\uc720\uc6a9\ud568",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"recommendation table\uc5d0 access\ud560 \uc218 \uc788\ub294 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc774 \ud2b9\uc815 \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud574 query"),(0,l.kt)("li",{parentName:"ul"},"\ucd94\ucc9c\ud560 3\uac1c\uc758 \ucf54\uc2a4\ub97c \uc989\uc2dc \uc5bb\uc744 \uc218 \uc788\uc74c")))))),(0,l.kt)("p",null,"Recommendation technique"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"rating table\uc744 recommendation \uc73c\ub85c \ubcc0\ud658 \uac00\ub2a5",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"matrix frctorization")))),(0,l.kt)("p",null,"Average course ratings"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"course_id, avg_rating"),(0,l.kt)("li",{parentName:"ul"},"\ub192\uc740 \ub4f1\uae09\uc758 \ucf54\uc2a4\ub97c \ucd94\ucc9c\ud558\uace0 \uc2f6\uae30 \ub54c\ubb38\uc5d0 \uc774 table\uc774 \uc720\uc6a9\ud560 \uac83")),(0,l.kt)("p",null,"Use the right programming language"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uc0ac\uc6a9\uc790\uac00 \uad00\uc2ec\uc744 \uac16\ub294 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\ub85c \ub41c \uac15\uc88c \ucd94\ucc9c"),(0,l.kt)("li",{parentName:"ul"},"\uacfc\uc815\ubcc4 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc5d0 \ub300\ud55c data, \uc5b4\ub5a4 \uacfc\uc815\uc744 \ud3c9\uac00\ud558\ub294\uc9c0\uc5d0 \ub300\ud55c data"),(0,l.kt)("li",{parentName:"ul"},"SQL \uacfc\uc815 2\uac1c\ub97c \ud3ec\ud568\ud558\uc5ec 4\uac1c \uacfc\uc815\uc744 \ud3c9\uac00\ud558\uba74 \ub2e4\uc74c SQL \uacfc\uc815\uc744 \ucd94\ucc9c")),(0,l.kt)("p",null,"Recommend new course"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uc0ac\uc6a9\uc790\uac00 \ud3c9\uac00\ud558\uc9c0 \uc54a\uc740 \ucf54\uc2a4 \ucd94\ucc9c"),(0,l.kt)("li",{parentName:"ul"},"user_id, course_id combination\uc774 rating table\uc5d0 \uc788\uc73c\uba74 \uc548\ub428")),(0,l.kt)("p",null,"\ucd94\ucc9c \uc804\ub7b5"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\uc0ac\uc6a9\uc790\uac00 \ub300\ubd80\ubd84 \ucf54\uc2a4\ub97c \ud3c9\uac00\ud55c \uae30\uc220\uc758 \ucf54\uc2a4 \ucd94\ucc9c"),(0,l.kt)("li",{parentName:"ul"},"\ud574\ub2f9 \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud574 \uc774\ubbf8 \ud3c9\uac00\ub41c \ucf54\uc2a4\ub294 \ucd94\ucc9c\ud558\uc9c0 \uc54a\uc74c"),(0,l.kt)("li",{parentName:"ul"},"\uac00\uc7a5 \ub192\uc740 \ub4f1\uae09\uc744 \uc720\uc9c0\ud558\ub294 \uc138 \uac00\uc9c0 \ucf54\uc2a4 \ucd94\ucc9c")),(0,l.kt)("p",null,"Filter out corrupt data"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'course_data = extract_course_data(db_engines)\n\n# Print out the number of missing values per column\nprint(course_data.isnull().sum())\n\n# The transformation should fill in the missing values\ndef transform_fill_programming_language(course_data):\n    imputed = course_data.fillna({"programming_language": "R"})\n    return imputed\n\ntransformed = transform_fill_programming_language(course_data)\n\n# Print out the number of missing values per column of transformed\nprint(transformed.isnull().sum())\n')),(0,l.kt)("p",null,"Using the recommender transformation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Complete the transformation function\ndef transform_recommendations(avg_course_ratings, courses_to_recommend):\n    # Merge both DataFrames\n    merged = courses_to_recommend.merge(avg_course_ratings) \n    # Sort values by rating and group by user_id\n    grouped = merged.sort_values("rating", ascending=False).groupby("user_id")\n    # Produce the top 3 values and sort by user_id\n    recommendations = grouped.head(3).sort_values("user_id").reset_index()\n    final_recommendations = recommendations[["user_id", "course_id","rating"]]\n    # Return final recommendations\n    return final_recommendations\n\n# Use the function with the predefined DataFrame objects\nrecommendations = transform_recommendations(avg_course_ratings, courses_to_recommend)\n')),(0,l.kt)("p",null,"\uc9c0\uae08\uae4c\uc9c0 \ud55c \uac83\ub4e4"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"extract_course_data()"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"extract_raing_data()"),"\ub97c \uc0ac\uc6a9\ud558\uc5ec courses \ubc0f rating \ud14c\uc774\ube14\uc5d0\uc11c \ub370\uc774\ud130 Extract "),(0,l.kt)("li",{parentName:"ul"},"courses \ud14c\uc774\ube14\uc5d0\uc11c missing value clean up using transform_fill_programming_language()"),(0,l.kt)("li",{parentName:"ul"},"\ucf54\uc2a4 \ub2f9 \ud3c9\uade0 \ucf54\uc2a4 rating\uc744 \uc5bb\uae30\uc704\ud574 \uc9d1\uacc4 \ud568\uc218 \uc81c\uc791: transform_avg_rating()"),(0,l.kt)("li",{parentName:"ul"},"\uc801\ud569\ud55c \uc0ac\uc6a9\uc790, \ucf54\uc2a4 id \uc30d\uc774 \uc788\ub294 DataFrame \uc5bb\uae30: transform_courses_to_recommend()"),(0,l.kt)("li",{parentName:"ul"},"recommendations \uacc4\uc0b0: transform_recommendations()")),(0,l.kt)("p",null,"Loading to Postgres"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"recommendation engine\ucc98\ub7fc data product\uc5d0\uc11c table \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c"),(0,l.kt)("li",{parentName:"ul"},"Airflow \uc791\uc5c5\uc758 \ubaa8\ub4e0 \uac83\uc744 \uc870\uc815\ud558\uc5ec \ud14c\uc774\ube14\uc744 \ub9e4\uc77c \ucd5c\uc2e0 \uc0c1\ud0dc\ub85c \uc720\uc9c0"),(0,l.kt)("li",{parentName:"ul"},"e.g. recommendations\uc744 \ud1b5\ud574 \ud2b9\uc815 \uace0\uac1d\uc5d0\uac8c \uc774\uba54\uc77c \ubcf4\ub0b4\uae30")),(0,l.kt)("p",null,"The loading phase"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\ud14c\uc774\ube14\uc5d0 \ub370\uc774\ud130\ub97c \uac00\uc838\uc624\uae30 \uc704\ud574 recommendations DataFrame\uc744 \uac00\uc838\uc624\uae30"),(0,l.kt)("li",{parentName:"ul"},"pandas\uc758 ",(0,l.kt)("inlineCode",{parentName:"li"},".to_sql()")," \uc0ac\uc6a9\ud558\uc5ec SQL \ud14c\uc774\ube14\uc5d0 \uc4f0\uae30",(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'recommendations.to_sql(\n    "recommendations", # \ud14c\uc774\ube14 \uc774\ub984\n    db_engine, # db engine\n    if_exitsts="append") # \ud14c\uc774\ube14 \uc874\uc7ac\ud558\ub294 \uacbd\uc6b0\uc5d0 \ub300\ud55c \uc804\ub7b5\n')))),(0,l.kt)("p",null,"etl()"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def etl(db_engines):\n    # Extract the data\n    courses = extract_course_data(db_engines)\n    rating = extract_rating_data(db_engines)\n    # Clean up courses data -> NA\ub97c \ucc44\uc6cc courses table \uc815\ub9ac\n    courses = transform_fill_programming_language(courses)\n    # Get the average course ratings\n    avg_course_rating = transform_avg_rating(rating)\n    # Get eligible user and course id pairs\n    courses_to_recommend = transform_courses_to_recommend(\n        rating,\n        courses,\n    )\n    # Calculate the recommendations\n    recommendations = transform_recommendations(\n        avg_course_rating,\n        courses_to_recommend,\n    )\n    # Load the recommendations into the database\n    load_to_dwh(recommendations, db_engine))\n")),(0,l.kt)("p",null,"Creating the DAG"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from airflow.models import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\ndag = DAG(dag_id="etl_pipeline",\n          schedule_interval="0 0 * * *")\ntask_recommendations = PythonOperator(\n    task_id="recommendations_task",\n    python_callable=etl,\n)\n')),(0,l.kt)("p",null,"The target table"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'connection_uri = "postgresql://repl:password@localhost:5432/dwh"\ndb_engine = sqlalchemy.create_engine(connection_uri)\n\ndef load_to_dwh(recommendations):\n    recommendations.to_sql("recommendations", db_engine, if_exists="replace")\n')),(0,l.kt)("p",null,"Defining the DAG"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Define the DAG so it runs on a daily basis\ndag = DAG(dag_id="recommendations",\n          schedule_interval="0 0 * * *")\n\n# Make sure `etl()` is called in the operator. Pass the correct kwargs.\ntask_recommendations = PythonOperator(\n    task_id="recommendations_task",\n    python_callable=etl,\n    op_kwargs={"db_engines": db_engines},\n)\n')),(0,l.kt)("p",null,"Querying the recommendations"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'def recommendations_for_user(user_id, threshold=4.5):\n    # Join with the courses table\n    query = """\n    SELECT title, rating FROM recommendations\n    INNER JOIN courses ON courses.course_id = recommendations.course_id\n    WHERE user_id=%(user_id)s AND rating>%(threshold)s\n    ORDER BY rating DESC\n    """\n    # Add the threshold parameter\n    predictions_df = pd.read_sql(query, db_engine, params = {"user_id": user_id, \n                                                             "threshold": threshold})\n    return predictions_df.title.values\n\n# Try the function you created\nprint(recommendations_for_user(12, 4.65))\n')))}s.isMDXComponent=!0}}]);