"use strict";(self.webpackChunkmy_blog=self.webpackChunkmy_blog||[]).push([[2302],{3905:(e,t,a)=>{a.d(t,{Zo:()=>s,kt:()=>d});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var m=n.createContext({}),o=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},s=function(e){var t=o(e.components);return n.createElement(m.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},k=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,m=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),k=o(a),d=r,N=k["".concat(m,".").concat(d)]||k[d]||u[d]||i;return a?n.createElement(N,l(l({ref:t},s),{},{components:a})):n.createElement(N,l({ref:t},s))}));function d(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=k;var p={};for(var m in t)hasOwnProperty.call(t,m)&&(p[m]=t[m]);p.originalType=e,p.mdxType="string"==typeof e?e:r,l[1]=p;for(var o=2;o<i;o++)l[o]=a[o];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}k.displayName="MDXCreateElement"},8311:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>p,toc:()=>o});var n=a(7462),r=(a(7294),a(3905));const i={title:"Data Engineering \uc2a4\ud130\ub514 15\uc8fc\ucc28",date:"2021-11-24",tags:["Data Engineering"],draft:!1,description:"PseudoLab Data Science Fellowship 1\uae30",sidebar_position:1},l="Introduction to PySpark",p={unversionedId:"Study/data-engineering/data-engineer-with-python-week-15",id:"Study/data-engineering/data-engineer-with-python-week-15",title:"Data Engineering \uc2a4\ud130\ub514 15\uc8fc\ucc28",description:"PseudoLab Data Science Fellowship 1\uae30",source:"@site/docs/Study/data-engineering/data-engineer-with-python-week-15.md",sourceDirName:"Study/data-engineering",slug:"/Study/data-engineering/data-engineer-with-python-week-15",permalink:"/docs/Study/data-engineering/data-engineer-with-python-week-15",draft:!1,editUrl:"https://github.com/teddygood/teddygood.github.io/docs/Study/data-engineering/data-engineer-with-python-week-15.md",tags:[{label:"Data Engineering",permalink:"/docs/tags/data-engineering"}],version:"current",sidebarPosition:1,frontMatter:{title:"Data Engineering \uc2a4\ud130\ub514 15\uc8fc\ucc28",date:"2021-11-24",tags:["Data Engineering"],draft:!1,description:"PseudoLab Data Science Fellowship 1\uae30",sidebar_position:1},sidebar:"sidebar",previous:{title:"Data Engineering \uc2a4\ud130\ub514 13\uc8fc\ucc28",permalink:"/docs/Study/data-engineering/data-engineer-with-python-week-13"},next:{title:"Data Engineering \uc2a4\ud130\ub514 16\uc8fc\ucc28",permalink:"/docs/Study/data-engineering/data-engineer-with-python-week-16"}},m={},o=[{value:"Getting to know PySpark",id:"getting-to-know-pyspark",level:2},{value:"Spark",id:"spark",level:3},{value:"Spark Data Structure",id:"spark-data-structure",level:3},{value:"Manipulating data",id:"manipulating-data",level:2},{value:"Selecting",id:"selecting",level:3},{value:"Aggregating",id:"aggregating",level:3},{value:"Joining",id:"joining",level:3},{value:"Getting started with machine learning pipelines",id:"getting-started-with-machine-learning-pipelines",level:2},{value:"Machine learning pipeline",id:"machine-learning-pipeline",level:3},{value:"Data type",id:"data-type",level:3},{value:"Strings and factors",id:"strings-and-factors",level:3},{value:"Assemble a vector",id:"assemble-a-vector",level:3},{value:"Create the pipeline",id:"create-the-pipeline",level:3},{value:"Test vs Train",id:"test-vs-train",level:3},{value:"Transform and Split the data",id:"transform-and-split-the-data",level:3},{value:"Model tuning and selection",id:"model-tuning-and-selection",level:2},{value:"Logistic regression",id:"logistic-regression",level:3},{value:"Cross validation",id:"cross-validation",level:3},{value:"Create the evaluator",id:"create-the-evaluator",level:3},{value:"Make a grid",id:"make-a-grid",level:3},{value:"Make the validator",id:"make-the-validator",level:3},{value:"Fit the model",id:"fit-the-model",level:3},{value:"Evaluating binary classifiers",id:"evaluating-binary-classifiers",level:3}],s={toc:o};function u(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"introduction-to-pyspark"},"Introduction to PySpark"),(0,r.kt)("h2",{id:"getting-to-know-pyspark"},"Getting to know PySpark"),(0,r.kt)("h3",{id:"spark"},"Spark"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Spark"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"cluster computing\uc744 \uc704\ud55c \ud50c\ub7ab\ud3fc"),(0,r.kt)("li",{parentName:"ul"},"\uac01 \ub178\ub4dc\ub97c \ucef4\ud4e8\ud130\ub85c \uc0dd\uac01\ud558\uc5ec \ub370\uc774\ud130\uc640 \uacc4\uc0b0\uc744 \uc5ec\ub7ec \ub178\ub4dc\uac00 \uc788\ub294 cluster\uc5d0 \ubd84\uc0b0\uc2dc\ud0ac \uc218 \uc788\uc74c "),(0,r.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130\ub97c \ubd84\ud560\ud558\uba74 \uac01 \ub178\ub4dc\uac00 \uc801\uc740 \uc591\uc758 \ub370\uc774\ud130\ub85c\ub9cc \uc791\ub3d9\ud558\ubbc0\ub85c \ub9e4\uc6b0 \ud070 \ub370\uc774\ud130\uc14b\uc73c\ub85c \uc791\uc5c5\ud558\uae30 \uc26c\uc6cc\uc9d0"),(0,r.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130 \ucc98\ub9ac\uc640 \uacc4\uc0b0\uc774 cluster\uc758 \ub178\ub4dc\uc5d0\uc11c \ubcd1\ub82c\ub85c \uc218\ud589\ub428",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\ud2b9\uc815 \uc720\ud615\uc758 \ud504\ub85c\uadf8\ub798\ubc0d \uc791\uc5c5\uc744 \ube60\ub974\uac8c \ud560 \uc218 \uc788\uc74c"),(0,r.kt)("li",{parentName:"ul"},"\ucef4\ud4e8\ud305 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub420\uc218\ub85d \ubcf5\uc7a1\uc131\uc740 \ub354 \ucee4\uc9d0"))),(0,r.kt)("li",{parentName:"ul"},"\uc2a4\ud30c\ud06c \uc0ac\uc6a9 \uc804 \uace0\ub824\ud574\ubcfc \uc810",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\ucef4\ud4e8\ud130 \ud55c \ub300\uc5d0\uc11c \uc791\uc5c5\ud558\uae30\uc5d0\ub294 \ub370\uc774\ud130\uac00 \ub108\ubb34 \ud070\uac00?"),(0,r.kt)("li",{parentName:"ul"},"\uacc4\uc0b0\uc744 \uc27d\uac8c \ubcd1\ub82c\ud654\ud560 \uc218 \uc788\ub294\uac00?"))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\uc911\uc2ec \ucef4\ud4e8\ud130\ub97c master\ub77c\uace0 \uc815\uc758\ud558\uba70 master\uc5d0 \uc5f0\uacb0\ub418\uc5b4 \uc788\ub294 \ucef4\ud4e8\ud130\ub97c worker\ub77c\uace0 \uc815\uc758"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc5f0\uacb0\ub418\uc5b4 \uc788\ub294 worker\uc5d0 \ub370\uc774\ud130\ub97c \ubcf4\ub0b4\uace0 \uacc4\uc0b0\uc744 \uc2e4\ud589\ud558\ub3c4\ub85d \ud568"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\ube45\ub370\uc774\ud130\uc640 \uac19\uc774 \ubcf5\uc7a1\ud55c \uc791\uc5c5\uc744 \uc704\ud574 \uc124\uacc4\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc791\uc740 \uc791\uc5c5\uc744 \ud560 \ub54c\ub294 \ud6a8\uc728\uc801\uc774\uc9c0 \uc54a\uc74c")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"PySpark\uc5d0\uc11c Spark cluster\uc5d0 \uc5f0\uacb0\ud558\ub294 \ubc29\ubc95"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"sc"),"\ub77c\uace0 \ubd88\ub9ac\ub294 ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkContext")," class\uc758 instance\ub97c \uc0dd\uc131"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Verify SparkContext\nprint(sc)\n\n# Print Spark version\nprint(sc.version)\n")))))),(0,r.kt)("h3",{id:"spark-data-structure"},"Spark Data Structure"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\uc2a4\ud30c\ud06c\uc758 \ud575\uc2ec \uc790\ub8cc\uad6c\uc870\ub294 ",(0,r.kt)("inlineCode",{parentName:"p"},"Resilient Distributed Dataset(RDD)")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"RDD\ub294 \uc9c1\uc811 \uc791\uc5c5\ud558\uae30 \uc5b4\ub835\uae30 \ub54c\ubb38\uc5d0 RDD \uc704\uc5d0 \uad6c\ucd95\ub41c Spark ",(0,r.kt)("inlineCode",{parentName:"li"},"DataFrame"),"\uc744 \uc0ac\uc6a9"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"DataFrame")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"SQL table\uacfc \uc720\uc0ac")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\uc774\ud574\ud558\uae30 \uc26c\uc6b0\uba70 RDD\ubcf4\ub2e4 \ubcf5\uc7a1\ud55c \uc791\uc5c5\uc5d0 \ub354 \ucd5c\uc801\ud654\uac00 \ub418\uc5b4 \uc788\uc74c")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"RDD"),"\ub97c \uc0ac\uc6a9\ud560 \ub54c\ub294 query\ub97c \ucd5c\uc801\ud654\ud558\ub294 \uc88b\uc740 \ubc29\ubc95\uc744 \ucc3e\ub294 \uac83\uc740 data scientist\uac00 \ud574\uc57c \ud558\uc9c0\ub9cc, ",(0,r.kt)("inlineCode",{parentName:"p"},"DataFrame"),"\uc740 \uc8c4\uc801\ud654 \uae30\ubc95\uc774 \ub9ce\uc774 \ub0b4\uc7a5\ub418\uc5b4 \uc788\uc74c")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"DataFrame\uc744 \uc0ac\uc6a9\ud558\ub824\uba74 ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkContext")," \ud074\ub798\uc2a4\uc5d0\uc11c ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession")," \uac1d\uccb4\ub97c \uc0dd\uc131\ud574\uc57c \ud568"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"SaprkContext"),"\ub294 cluster\uc5d0 \ub300\ud55c \uc5f0\uacb0, ",(0,r.kt)("inlineCode",{parentName:"li"},"SparkSession"),"\uc740 \ud574\ub2f9 \uc5f0\uacb0\uc5d0 \ub300\ud55c interface\ub77c\uace0 \uc0dd\uac01\ud560 \uc218 \uc788\uc74c"),(0,r.kt)("li",{parentName:"ul"},"\ub2e4\uc218\uc758 SparkSession\uacfc SparkContext\ub97c \uc0dd\uc131\ud558\uba74 \ubb38\uc81c\uac00 \ub420 \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0 \uac00\uc7a5 \uc88b\uc740 \ubc29\ubc95\uc740 ",(0,r.kt)("inlineCode",{parentName:"li"},"SparkSession.builder.getOrCreate()")," \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9 ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"SparkSession\uc774 \uc788\uc73c\uba74 \uadf8\uac78 \uc0ac\uc6a9\ud558\uace0 \uc5c6\uc73c\uba74 \uc0c8\ub85c \uc0dd\uc131"))),(0,r.kt)("li",{parentName:"ul"},"SparkSession \uc0dd\uc131",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Import SparkSession from pyspark.sql\nfrom pyspark.sql import SparkSession\n# Create my_spark\nspark = SparkSession.builder.getOrCreate()\n# Print my_spark\nprint(spark)\n"))),(0,r.kt)("li",{parentName:"ul"},"SparkSession\uc5d0\ub294 cluster\uc758 \ubaa8\ub4e0 \ub370\uc774\ud130\ub97c \ub9ac\uc2a4\ud2b8\ub85c \ub098\uc5f4\ud558\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"catalog"),"\ub77c\ub294 attribute\uac00 \uc788\uc73c\uba70, \ub2e4\uc591\ud55c \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\ub294 \uba54\uc11c\ub4dc\uac00 \uc874\uc7ac",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"cluster\uc5d0 \uc788\ub294 \ubaa8\ub4e0 \ud14c\uc774\ube14\uc758 \uc774\ub984\uc744 list\ub85c return\ud558\ub294 listTables() \uba54\uc11c\ub4dc \uc0ac\uc6a9",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"print(spark.catalog.listTables())\n"))))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"DataFrame\uc758 \uc7a5\uc810 \uc911 \ud558\ub098\ub294 Spark cluster\uc758 \ud14c\uc774\ube14\uc5d0\uc11c SQL query\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4\ub294 \uac83"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"sql()")," \uba54\uc11c\ub4dc \uc0ac\uc6a9"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"DataFrame \ubc18\ud658")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Don\'t change this query\nquery = "FROM flights SELECT * LIMIT 10"\n\n# Get the first 10 rows of flights\nflights10 = spark.sql(query)\n\n# Show the results\nflights10.show()\n'))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Pandas \uc0ac\uc6a9"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"toPandas()"),": \uacb0\uacfc\ub97c pandas DataFrame\uc73c\ub85c \ubcc0\ud658"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Don\'t change this query\nquery = "SELECT origin, dest, COUNT(*) as N FROM flights GROUP BY origin, dest"\n\n# Run the query\nflight_counts = spark.sql(query)\n\n# Convert the results to a pandas DataFrame\npd_counts = flight_counts.toPandas()\n\n# Print the head of pd_counts\nprint(pd_counts.head())\n'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"createDataFrame()"),": pandas DataFrame\uc744 \uc0ac\uc6a9\ud558\uace0 Spark DataFrame\uc744 \ubc18\ud658"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc6d0\ubcf8\uc5d0\ub294 \ubcc0\ud654\uac00 \uc5c6\uae30 \ub54c\ubb38\uc5d0 ",(0,r.kt)("inlineCode",{parentName:"li"},"createTempView()")," \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc774 \ubc29\ubc95\ub3c4 \uc784\uc2dc\uc801\uc778 table\uc744 \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc774\uae30 \ub54c\ubb38\uc5d0 \ud2b9\uc815 SparkSession\uc5d0\uc11c\ub9cc \uc0ac\uc6a9 \uac00\ub2a5"),(0,r.kt)("li",{parentName:"ul"},"\ub300\uc2e0 ",(0,r.kt)("inlineCode",{parentName:"li"},"createOrReplaceTempView()")," \uba54\uc11c\ub4dc \uc0ac\uc6a9",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc774\uc804\uc5d0 \uc544\ubb34\uac83\ub3c4 \uc5c6\uc5c8\uc73c\uba74 \uc784\uc2dc \ud14c\uc774\ube14\uc744 \uc548\uc804\ud558\uac8c \uc0dd\uc131\ud558\uace0 \uc815\uc758\ub41c \uacbd\uc6b0\uba74 \uae30\uc874 \ud14c\uc774\ube14\uc744 \uc5c5\ub370\uc774\ud2b8\ud568"),(0,r.kt)("li",{parentName:"ul"},"\uc911\ubcf5\uc73c\ub85c \ud14c\uc774\ube14\uc744 \ub9cc\ub4dc\ub294 \ubb38\uc81c\ub97c \ubc1c\uc0dd\uc2dc\ud0a4\uc9c0 \uc54a\uc74c")))))),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Create pd_temp\npd_temp = pd.DataFrame(np.random.random(10))\n\n# Create spark_temp from pd_temp\nspark_temp = spark.createDataFrame(pd_temp)\n\n# Examine the tables in the catalog\nprint(spark.catalog.listTables())\n\n# Add spark_temp to the catalog\nspark_temp.createOrReplaceTempView('temp')\n\n# Examine the tables in the catalog again\nprint(spark.catalog.listTables())\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"read()")," \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec csv \uc77d\uae30"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Don\'t change this file path\nfile_path = "/usr/local/share/datasets/airports.csv"\n\n# Read in the airports data\nairports = spark.read.csv(file_path, header=True)\n\n# Show the data\nairports.show()\n')))))))),(0,r.kt)("h2",{id:"manipulating-data"},"Manipulating data"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Spark DataFrame\uc740 immutable",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\ub36e\uc5b4\uc4f0\uae30\ub97c \ud558\ub824\uba74 \ubc18\ud658\ub41c Dataframe\uc744 \ub2e4\uc2dc \ud560\ub2f9\ud574\uc57c \ud568"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"withColumn()")," \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec Column \ub2e8\uc704 \uc5f0\uc0b0 \uc0ac\uc6a9",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc0c8\ub85c\uc6b4 column \uc774\ub984, \uc0c8\ub85c\uc6b4 column")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'df = df.withColumn("newCol", df.oldCol + 1)\n'))))),(0,r.kt)("li",{parentName:"ul"},"SQL\uc5d0\ub294 WHERE \ubb38\uc774 \uc788\ub4ef\uc774, Spark DataFrame\uc5d0\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"filtering()")," \uba54\uc11c\ub4dc \uc874\uc7ac",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"WHERE \ubb38\uc5d0 \ub4e4\uc5b4\uac08 \uc218 \uc788\ub294 \ubaa8\ub4e0 \ud45c\ud604\uc744 \ud5c8\uc6a9")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'flights.filter("air_time > 120").show()\nflights.filter(flights.air_time > 120).show()\n')))),(0,r.kt)("h3",{id:"selecting"},"Selecting"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Spark\uc5d0\uc11c\ub294 SELECT \ub300\uc2e0 ",(0,r.kt)("inlineCode",{parentName:"p"},"select()")," \uba54\uc11c\ub4dc \uc0ac\uc6a9"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"withColumn()"),"\uacfc \ucc28\uc774\uc810",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"select()"),"\ub294 \uc9c0\uc815\ud55c column\ub9cc return"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"withColumn()"),"\uc740 \uc0ac\uc6a9\uc790\uac00 \uc815\uc758\ud55c column \ub9d0\uace0\ub3c4 DataFrame\uc758 \ubaa8\ub4e0 column\uc744 return")))),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Select the first set of columns\nselected1 = flights.select("tailnum","origin", "dest")\n\n# Select the second set of columns\ntemp = flights.select(flights.origin, flights.dest, flights.carrier)\n\n# Define first filter\nfilterA = flights.origin == "SEA"\n\n# Define second filter\nfilterB = flights.dest == "PDX"\n\n# Filter the data, first by filterA then by filterB\nselected2 = temp.filter(filterA).filter(filterB)\n')),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"column \ub2e8\uc704\uc758 \uc5f0\uc0b0 \uac00\ub2a5",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"flights.select(flights.air_time/60)\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"alias()")," \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uba74 SQL\uc758 ",(0,r.kt)("inlineCode",{parentName:"li"},"as"),"\ucc98\ub7fc \uc120\ud0dd\ud55c column\uc758 \uc774\ub984\uc744 \uc7ac\uc124\uc815\ud560 \uc218 \uc788\uc74c ",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'flights.select((flights.air_time/60).alias("duration_hrs"))\n'))),(0,r.kt)("li",{parentName:"ul"},"SQL \ud45c\ud604\uc2dd\uc744 \ubb38\uc790\uc5f4\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"selectExpr"),"\uc744 \uc0ac\uc6a9\ud558\uc5ec ",(0,r.kt)("inlineCode",{parentName:"li"},"SELECT"),"\ub97c \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc74c")))),(0,r.kt)("h3",{id:"aggregating"},"Aggregating"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"min(), max() \uac19\uc740 aggregation \uba54\uc11c\ub4dc\ub3c4 .groupBy() \uba54\uc11c\ub4dc\ub85c ",(0,r.kt)("inlineCode",{parentName:"p"},"<pyspark.sql.group.GroupedData>"),"\ub97c \ub9cc\ub4e0 \ud6c4 \uc0ac\uc6a9"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'df.groupBy().min("col").show()\n'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\ud55c \uc904\ub85c \ud45c\ud604\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c \ub098\ub220\uc11c\ub3c4 \uc0ac\uc6a9 \uac00\ub2a5"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'by_plane = flights.groupBy("tailnum")\nby_plane.count().show()\n'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"groupBy()")," \ub300\uc2e0 ",(0,r.kt)("inlineCode",{parentName:"p"},"agg()"),"\ub97c \uc0ac\uc6a9\ud558\uc5ec aggregation \ud45c\ud604\uc2dd \uc804\ub2ec"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"pyspark.sql.functions")," submodule\uc758 aggregation \ud568\uc218 \uc0ac\uc6a9"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import pyspark.sql.functions as F\n\nby_month_dest.agg(F.stddev("dep_delay")).show()\n')))))),(0,r.kt)("h3",{id:"joining"},"Joining"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"PySpark\uc5d0\uc11c\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"join()")," \uba54\uc11c\ub4dc \uc0ac\uc6a9",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"DataFrame\uacfc \uacb0\ud569\ud560 \ub2e4\ub978 DataFrame, \uc5b4\ub514\uc5d0\uc11c join\ud560 \uc9c0 \uacb0\uc815\ud558\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"on"),", \ubc29\ubc95\uc744 \uacb0\uc815\ud558\ub294 how")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'flights_with_airports = flights.join(airports, on="dest", how="leftouter")\n')))),(0,r.kt)("h2",{id:"getting-started-with-machine-learning-pipelines"},"Getting started with machine learning pipelines"),(0,r.kt)("h3",{id:"machine-learning-pipeline"},"Machine learning pipeline"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"pyspark.ml",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Transformer"),": DataFrame\uc744 column\uc774 \ucd94\uac00\ub3c4\ub2c8 \ub2e4\ub978 DataFrame\uc73c\ub85c \ubcc0\ud658\ud574\uc8fc\ub294 \uc54c\uace0\ub9ac\uc998\ub4e4\uc744 \uc758\ubbf8",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"transform()")," \uba54\uc11c\ub4dc \uc0ac\uc6a9"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"Estimator"),": Transformer\uc5d0 \uc758\ud574 \uc0dd\uc131\ub41c DataFrame\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\uc744 \uc9c4\ud589\ud558\uace0 \ubaa8\ub378\uc744 \uc0dd\uc131\ud558\ub294 \uc54c\uace0\ub9ac\uc998\ub4e4",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"fit()")," \uba54\uc11c\ub4dc \uc0ac\uc6a9")))))),(0,r.kt)("h3",{id:"data-type"},"Data type"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Spark\ub294 \ubaa8\ub378\ub9c1\uc744 \ud560 \ub54c numeric data\ub9cc \ub2e4\ub8f0 \uc218 \uc788\uc74c")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Spark DataFrame\uc740 \ub370\uc774\ud130\ub97c \uac00\uc838\uc62c \ub54c \uac01 column\uc5d0 \uc5b4\ub5a4 \ud0c0\uc785\uc778\uc9c0 \ucd94\uce21\uc744 \ud568"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Spark\uac00 \uc81c\ub300\ub85c \ucd94\uce21\ud558\uc9c0 \ubabb\ud560 \ub54c\ub294 ",(0,r.kt)("inlineCode",{parentName:"p"},"withColumn()")," \uba54\uc11c\ub4dc\uc640 ",(0,r.kt)("inlineCode",{parentName:"p"},"cast()")," \uba54\uc11c\ub4dc\ub97c \uac19\uc774 \uc0ac\uc6a9"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"cast()"),"\ub294 column\uc5d0\uc11c \uc791\ub3d9\ud558\uace0 ",(0,r.kt)("inlineCode",{parentName:"li"},"withColumn()"),"\uc740 DataFrame\uc5d0\uc11c \uc791\ub3d9")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"dataframe = dataframe.withColumn('column_name', dataframe.column_name.cast('integer'))\n")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\ub370\uc774\ud130\ub97c boolean \ud45c\ud604\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec True/False\ub85c \ub098\ub204\uace0 integer\ub85c \ubc14\uafbc \ud6c4 missing value\ub97c \uc0ad\uc81c\ud558\ub294 \uc608\uc2dc"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Create is_late\nmodel_data = model_data.withColumn("is_late", model_data.arr_delay > 0)\n\n# Convert to an integer\nmodel_data = model_data.withColumn("label", model_data.is_late.cast(\'integer\'))\n\n# Remove missing values\nmodel_data = model_data.filter("arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL and plane_year is not NULL")\n')))))))),(0,r.kt)("h3",{id:"strings-and-factors"},"Strings and factors"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Spark\ub294 \ubaa8\ub378\ub9c1\uc744 \ud560 \ub54c numeric data \ubc16\uc5d0 \ucc98\ub9ac\ud558\uc9c0 \ubabb \ud558\uae30 \ub54c\ubb38\uc5d0 string data\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 \ub370\uc774\ud130\ub97c \uc218\uc815\ud574\uc57c \ud568",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"one-hot vector/encoding",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"pyspark.ml.feature")," submodule\uc5d0 \uae30\ub2a5\uc774 \ub0b4\uc7a5\ub418\uc5b4 \uc788\uc74c"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"pyspark.ml.feature.StringIndexer"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"string column\uc774 \uc788\ub294 DataFrame\uc744 \uc0ac\uc6a9\ud558\uace0 \uace0\uc720\ud55c string\uc744 \uc22b\uc790\uc5d0 mapping\ud558\ub294 Estimator"),(0,r.kt)("li",{parentName:"ul"},"DataFrame\ub97c \uc785\ub825 \ubc1b\uc544 Transformer\ub97c \ubc18\ud658\ud558\uace0 mapping\ud55c \uac83\uc744 metadata\ub85c \ucca8\ubd80\ud55c \ud6c4, string column\uc5d0 \ud574\ub2f9\ud558\ub294 numeric column\uc774 \uc874\uc7ac\ud558\ub294 \uc0c8\ub85c\uc6b4 DataFrame\uc744 \ubc18\ud658"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"pyspark.ml.feature.OneHotEncoder"),"\ub97c \uc0ac\uc6a9\ud558\uc5ec one-hot encoding \uc9c4\ud589",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Estimator\ub97c \uc0dd\uc131 \ud6c4 Transformer\ub97c \uc0ac\uc6a9\ud558\ub294 StringIndexer\uc640 \ub3d9\uc77c\ud558\uac8c \uc791\ub3d9"))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\ub2e8\uc5b4 \uc9d1\ud569\uc758 \ud06c\uae30\ub97c \ubca1\ud130\uc758 dimension\uc73c\ub85c \ud558\uace0 \ud45c\ud604\ud558\uace0 \uc2f6\uc740 \ub2e8\uc5b4\uc758 index\uc5d0 1, \ub2e4\ub978 index\uc5d0 0\uc744 \ubd80\uc5ec\ud558\ub294 \ubca1\ud130 \ud45c\ud604 \ubc29\uc2dd")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"example"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Create a StringIndexer\ncarr_indexer = StringIndexer(inputCol="carrier", outputCol="carrier_index")\n\n# Create a OneHotEncoder\ncarr_encoder = OneHotEncoder(inputCol="carrier_index", outputCol="carrier_fact")\n')))))))),(0,r.kt)("h3",{id:"assemble-a-vector"},"Assemble a vector"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\ud30c\uc774\ud504\ub77c\uc778\uc758 \ub9c8\uc9c0\ub9c9 \ub2e8\uacc4\ub294 feature\ub97c \ud3ec\ud568\ud558\ub294 \ubaa8\ub4e0 \uc5f4\uc744 \ub2e8\uc77c \uc5f4\ub85c \uacb0\ud569\ud558\ub294 \uac83",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"VectorAssembler"),"\ub77c\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"Transformer"),"\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubca1\ud130\ud654",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'vec_assembler = VectorAssembler(inputCols=["month", "air_time", "carrier_fact", "dest_fact", "plane_age"], outputCol="features")\n')))))),(0,r.kt)("h3",{id:"create-the-pipeline"},"Create the pipeline"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Import Pipeline\nfrom pyspark.ml import Pipeline\n\n# Make the pipeline\nflights_pipe = Pipeline(stages=[dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])\n")),(0,r.kt)("h3",{id:"test-vs-train"},"Test vs Train"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\uac00\uc7a5 \uc911\uc694\ud55c \ub2e8\uacc4\ub294 data\ub97c test set\uacfc train set\uc73c\ub85c \ub098\ub204\ub294 \ub2e8\uacc4"),(0,r.kt)("li",{parentName:"ul"},"Spark\uc5d0\uc11c\ub294 transformer \uc9c4\ud589 \ud6c4 \ub370\uc774\ud130\ub97c \ubd84\ud560")),(0,r.kt)("h3",{id:"transform-and-split-the-data"},"Transform and Split the data"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Fit and transform the data\npiped_data = flights_pipe.fit(model_data).transform(model_data)\n\n# Split the data into training and test sets\ntraining, test = piped_data.randomSplit([.6, .4])\n")),(0,r.kt)("h2",{id:"model-tuning-and-selection"},"Model tuning and selection"),(0,r.kt)("h3",{id:"logistic-regression"},"Logistic regression"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\uc120\ud615 \ud68c\uadc0(linear regression)"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc885\uc18d\ubcc0\uc218 Y\uc640 \ud55c \uac1c \uc774\uc0c1\uc758 \ub3c5\ub9bd\ubcc0\uc218 X\uc640\uc758 \uc120\ud615 \uc0c1\uad00\uad00\uacc4\ub97c \ubaa8\ub378\ub9c1\ud558\ub294 \ud68c\uadc0\ubd84\uc11d \uae30\ubc95"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\ub85c\uc9c0\uc2a4\ud2f1 \ud68c\uadc0(logistic regression)"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\ub370\uc774\ud130\uac00 \uc5b4\ub5a4 \ubc94\uc8fc\uc5d0 \uc18d\ud560 \ud655\ub960\uc744 0\uc5d0\uc11c 1 \uc0ac\uc774\uc758 \uac12\uc73c\ub85c \uc608\uce21\ud558\uace0 \uadf8 \ud655\ub960\uc5d0 \ub530\ub77c \uac00\ub2a5\uc131\uc774 \ub354 \ub192\uc740 \ubc94\uc8fc\uc5d0 \uc18d\ud558\ub294 \uac83\uc73c\ub85c \ubd84\ub958\ud574\uc8fc\ub294 \uc9c0\ub3c4 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998"),(0,r.kt)("li",{parentName:"ul"},"linear regression\uacfc \ub9e4\uc6b0 \uc720\uc0ac",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc120\ud615 \ud68c\uadc0\uc640\ub294 \uc870\uae08 \ub2e4\ub974\uac8c \uc885\uc18d \ubcc0\uc218\uac00 \ubc94\uc8fc\ud615 \ub370\uc774\ud130\ub97c \ub300\uc0c1\uc73c\ub85c \ud558\uba70 \uc785\ub825 \ub370\uc774\ud130\uac00 \uc8fc\uc5b4\uc84c\uc744 \ub54c \ud574\ub2f9 \ub370\uc774\ud130\uc758 \uacb0\uacfc\uac00 \ud2b9\uc815 \ubd84\ub958\ub85c \ub098\ub258\uae30 \ub54c\ubb38\uc5d0 \uc77c\uc885\uc758 \ubd84\ub958 \uae30\ubc95\uc73c\ub85c \ubcf4\uae30\ub3c4 \ud568 "))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"PySaprk\uc5d0\uc11c \uc0ac\uc6a9"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"pyspark.ml.classification"),"\uc5d0 \uc788\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"LogisticRegression")," Estimator \uc0ac\uc6a9")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Import LogisticRegression\nfrom pyspark.ml.classification import LogisticRegression\n\n# Create a LogisticRegression Estimator\nlr = LogisticRegression()\n")))),(0,r.kt)("h3",{id:"cross-validation"},"Cross validation"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"train set\uc73c\ub85c \ubaa8\ub378 \ud6c8\ub828, test set\uc73c\ub85c \ubaa8\ub378 \uac80\uc99d "),(0,r.kt)("li",{parentName:"ul"},"test set\uc5d0 overfitting\ud558\uac8c \ub418\ubbc0\ub85c \uc2e4\uc81c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uce21\uc744 \uc218\ud589\ud558\uba74 \uc88b\uc9c0 \uc54a\uc740 \uacb0\uacfc\uac00 \ub098\uc634",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uad50\ucc28 \uac80\uc99d(cross validation)\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud574\uacb0",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"train set\uc744 train set + validation set\uc73c\ub85c \ubd84\ub9ac\ud55c \ud6c4 validation set\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac80\uc99d\ud558\ub294 \ubc29\uc2dd"))))),(0,r.kt)("li",{parentName:"ul"},"\uc774\ubc88 \uc608\uc2dc\uc5d0\uc11c\ub294 k-fold cross validation \uc0ac\uc6a9")),(0,r.kt)("h3",{id:"create-the-evaluator"},"Create the evaluator"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"\ubaa8\ub378 \uc120\ud0dd\uc744 \uc704\ud55c \uad50\ucc28 \uac80\uc99d\uc744 \uc218\ud589\ud560 \ub54c \uac00\uc7a5 \ud544\uc694\ud55c \uac83\uc740 \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub378\uc744 \ube44\uad50\ud558\ub294 \uac83"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"pyspark.ml.evaluation"),"\uc5d0 \ube44\uad50\ub97c \uc704\ud55c class\ub4e4\uc774 \uc788\uc74c"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"binary classificaion model example"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Import the evaluation submodule\nimport pyspark.ml.evaluation as evals\n\n# Create a BinaryClassificationEvaluator\nevaluator = evals.BinaryClassificationEvaluator(metricName="areaUnderROC")\n')))))))),(0,r.kt)("h3",{id:"make-a-grid"},"Make a grid"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\ucd5c\uc801\uc758 hyperparameter\ub97c \ucc3e\uae30 \uc704\ud574 \uc0dd\uc131",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"pyspark.ml.tuning"),"\uc758 ",(0,r.kt)("inlineCode",{parentName:"li"},"ParamGridBuilder")," \uc0ac\uc6a9"),(0,r.kt)("li",{parentName:"ul"},"\uad50\ucc28 \uac80\uc99d\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \uadf8\ub9ac\ub4dc\ub97c \uc0dd\uc131\ud558\ub824\uba74 ",(0,r.kt)("inlineCode",{parentName:"li"},"addGrid()"),"\uc640 ",(0,r.kt)("inlineCode",{parentName:"li"},"build()")," \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud574\uc57c \ud568")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Import the tuning submodule\nimport pyspark.ml.tuning as tune\n\n# Create the parameter grid\ngrid = tune.ParamGridBuilder()\n\n# Add the hyperparameter\ngrid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\ngrid = grid.addGrid(lr.elasticNetParam, [0, 1])\n\n# Build the grid\ngrid = grid.build()\n")),(0,r.kt)("h3",{id:"make-the-validator"},"Make the validator"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"pyspark.ml.tuning"),"\uc5d0\ub294 cross validation\uc744 \uc9c4\ud589\ud558\ub294 ",(0,r.kt)("inlineCode",{parentName:"li"},"CrossValidator"),"\uac00 \uc874\uc7ac",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc774 Estimator\ub294 fit\ud558\ub824\ub294 model, \uc0dd\uc131\ud55c hyperparameter\uc758 grid, \ubaa8\ub378\uc744 \ube44\uad50\ud558\ub294 \ub370 \uc0ac\uc6a9\ud558\ub294 evaluator\ub97c \uc0ac\uc6a9")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## Create the CrossValidator\ncv = tune.CrossValidator(estimator=lr,\n               estimatorParamMaps=grid,\n               evaluator=evaluator\n               )\n")),(0,r.kt)("h3",{id:"fit-the-model"},"Fit the model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Fit cross validation models\nmodels = cv.fit(training)\n\n# Extract the best model\nbest_lr = models.bestModel\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Call lr.fit()\nbest_lr = lr.fit(training)\n\n# Print best_lr\nprint(best_lr)\n")),(0,r.kt)("h3",{id:"evaluating-binary-classifiers"},"Evaluating binary classifiers"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"AUC \ub610\ub294 area under the ROC(receiver operating characteristic) curve\ub77c\uace0 \ubd88\ub9ac\ub294 binary classification \uc54c\uace0\ub9ac\uc998 \uc0ac\uc6a9",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"binary classifier\ub294 \ub450 \uac00\uc9c0\uc758 \ud074\ub798\uc2a4\ub97c \ubd84\ub958\ud560 \uc218 \uc788\ub294 \ubd84\ub958\uae30"),(0,r.kt)("li",{parentName:"ul"},"\uc774\uc9c4 \ubd84\ub958\uae30\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294\ub370 \uc0ac\uc6a9\ud558\ub294 \uac83 \uc911 \ud558\ub098\uac00 AUC"),(0,r.kt)("li",{parentName:"ul"},"ROC curve\uc758 \uc544\ub798\ucabd \uba74\uc801"),(0,r.kt)("li",{parentName:"ul"},"\uc544\ub798\ucabd \uba74\uc801\uc774 \uc801\uc744\uc218\ub85d \ub9ce\uc774 \ud2c0\ub9bc"),(0,r.kt)("li",{parentName:"ul"},"1\uc5d0 \uac00\uae4c\uc6b8\uc218\ub85d \uc88b\uc740 \ubaa8\ub378")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Use the model to predict the test set\ntest_results = best_lr.transform(test)\n\n# compute the AUC.\nprint(evaluator.evaluate(test_results))\n")))}u.isMDXComponent=!0}}]);